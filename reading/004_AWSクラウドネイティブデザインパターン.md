# AWSクラウドネイティブデザインパターン

[AWSクラウドネイティブデザインパターン](https://direct.gihyo.jp/view/item/000000003465)

## はじめに

- アプリケーション変更頻度と品質は正の相関にある
  - 変更頻度が低いと品質が低下する
- クラウドネイティブの定義
  - クラウドの機能を活用して運用を効率化し、高度な回復力と可観測性を実現する
  - 結果として、障害やメンテ・アクセス急増などの日々の運用に工数をかける必要がなく、頻繁に自信を持ってアプリケーションを変更できる
- これを実現するためのプラクティスと設計パターンを「運用を効率化」「回復力」「可観測性」の2つの観点から紹介するのが本書である
- クラウドネイティブを実現するには「疎結合」が重要な概念
  - 疎結合なアーキテクチャとは「コントロール可能な部品を明確に定義されたインターフェイスで組み合わせるアーキテクチャ」のこと
  - インターフェイスのみ知っておけば、コンポーネント間を繋いでシステムを構築できる
  - これに役立つ技術がコンテナやサーバーレスになる
  - 「コントロール可能」とは、望む動作を得られたりするように、管理できているということ

# 第1部 運用を効率化する

## 1章 責任共有モデルを意識してアーキテクチャを選択する

- 責任範囲の最小化
  - 責任共有モデルを意識して、なるべく多くの運用をクラウドに移譲する
- 責任範囲のサポート
  - 利用者が担う責任をサポートする機能やサービスを使い倒す
    - [VPC Reachability Analyzer](https://docs.aws.amazon.com/vpc/latest/reachability/what-is-reachability-analyzer.html)でネットワークが目的通り設定されているかの確認が可能
    - AmazonInspectorで不要なネットワークパスが公開されていないかをスキャン
- 一言でまとめると..
  - **なるべくできるだけクラウド側に運用を任せられるアーキテクチャを選定しようぜ**

## 2章 テスト容易性を高める

- テスト容易性とは、アプリケーションに対してどれだけ簡単に、かつ効果的にテストができるかという性質
- クラウドネイティブアプリケーションでは、ユニットテストを充実させることが有用
  - ユニットテストは、自動化が容易で実行が高速だから
- テストがないコード＝レガシーコードであり、レガシーコードは簡潔にいうと「密結合」なコード
- とは言っても、テストがあれば良いのかというとそうでもなく、「高い信頼性」と「開発者主体で作成されていること」が効果的である
  - テストの信頼性とは？
    - 通ればリリースできるし、通らなければリリースできない
    - 同じテストなのに実行するたびに変わるのは、偽陽性が多くなり、開発デリバリーに悪影響
    - こうした問題には、依存関係を整理してユニットテストの比重を増やすのももちろん、そもそもそう言ったテストを削除してしまうのも良い
  -  開発者主体で作成された自動テストとは？
    - 外部に発注したテストもデリバリーに良い効果を齎せない
    - 開発者主体で行うからこそ、疎結合に作り、パフォーマンス向上が見込める

### テストピラミッドとCI/CD

- 「開発者に素早くフィードバックを返す環境が重要」という観点から有名な考え方がテストピラミッド
  - テスト戦略全体において、大部分（70％くらい）をユニットテストが占めるべきというもの
  - ユニットテストは低コストで自動化が容易と定義されている
  - 詳細：[第5回 テストピラミッド～自動テストの信頼性を中長期的に保つ最適なバランス～](https://gihyo.jp/dev/serial/01/savanna-letter/0005)
- CI/CDの原則は、各ステージで失敗したらすぐに開発を止めて、原因を突き止め、修正すべきとされている
  - テストピラミッドが崩れている（ユニットテストが少ないとか）とこの原則が形骸しがちなので注意
- 一言でまとめると..
  - **とりあえずユニットテストを書いて自動化して、CI/CDパイプラインで検知しようぜ**

### テスト容易性を高めるアーキテクチャパターン

#### 依存関係の逆転

- 例えば、イベント作成メソッドの内部に「メールで通知する」という実装が含まれている例
  - このメソッドのユニットテストを書こうとすると、メールで通知するという外部に依存する処理を書く必要がある
  - そこで、通知を送るというインターフェイスを用意して、インターフェイスという抽象に依存させることで、ユニットテストではこの部分をモック化するだけで良くなるので、テストがしやすくなる
- このように依存の向きを呼び出しの向きを逆にする＝イベント作成サービス側がインターフェイスを定義して、そのインターフェイスにメール送信処理が依存すること
- この原則は、上位と下位のレイヤ構造になっている依存関係全般に適用できる
  - 特に、メールや外部API、SaaSなど、アプリケーションで直接制御していない外部との連携部分で利用すると有用である

#### コンテナによる依存関係の注入

- Dockerを使用してデータベース等の環境を立ち上げてそこでテストする
- Testcontainersでテストコードから、コンテナを起動可能

#### コマンドとクエリの分離(CQS)

- コードのメソッドをコマンドとクエリのどちらかに分離すべきという原則
- 副作用が発生するコードを局所化し、テストの容易性を向上できる
  - ユニットテストで何をテストすべきか明確になるため

#### コマンドとクエリの責任分離(CQRS)

- CQSを発展させたもので、コマンドの責務を持つクラスとクエリの責務を持つクラスを分離するデザインパターン
- 例えば、ユーザーがどのチケットを買い、どのイベントに参加したか等のアクティビティをレポートする機能があるとする
  - シンプルに実装した場合、レポート機能メソッドで様々なクラスを呼び出して情報を集めることになる
  - こうなると多くのクラスに依存し、テストが容易ではない
  - ここでアクティビティを取得するクラスにクエリの責務を分離する(CQRS)
    - その中で実際のクエリを直接書くようにする
    - UserActivityRepositoryみたいなイメージ
  - 結果として、アクティビティの依存関係がシンプルになり、テストが容易になる

- この章を一言にまとめると..
  - **とりあえず疎結合に作って、ユニットテストしやすいようにDIとCQR(S)を意識し、CI/CDパイプラインをきちんと整備しよう**

## 3章 小規模かつ可逆的な変更を頻繁に行う

- クラウドネイティブなアプリケーションでは、様々な変更を、頻繁に、自信を持って行うことができる
- そのため小規模かつ可逆的な変更を積み重ねることが重要
  - いつでもロールバックできる小さな変更であれば頻繁に、自信を持って行うことができるだろう

### 継続的インテグレーション

- CI/CDの目的は、**開発に集中できる状況を作る**こと
- ブランチ戦略の話
  - 継続的にインテグレーションされた状態を維持するには、長命なブランチを最小限に抑える必要がある
  - 例えば、開発環境ブランチ・本番環境用ブランチのように、いくつも長命なブランチが増えると、リリースのプロセスは複雑になり、それぞれのコードベースのマージにかかる不具合や工数も増えてしまう

#### トランクベース開発

- 上記の考え方に沿って、長命なブランチ＝トランクを1つに限定する開発手法がある
  - 全ての開発をトランク上で行い、ブランチの利用は短命のものにする
- クラウドネイティブにおける「小規模かつ可逆的な変更を頻繁に行う」ためには、必須と言って良いほど重要(そもそも前提みたいなもの)
- 長命なブランチを多く活用することで、継続的インテグレーションが難しくなる理由
  - リリースの安全性が損なわれる
    - 長命ブランチが増えれば増えるほどマージにかかる工数やコンフリクトへの対処が発生する
    - また、Aブランチで改修したHoge関数を、Bブランチが改修前の状態のHoge関数を実行する箇所を追加したみたいな例だと不整合も発生する
  - リファクタリングが難しくなり、技術負債が積み上がる
    - リファクタリングすることにより、不整合が発生するということは、心理的にリファクタリングをしたくなる環境ではなくなる

### 継続的インテグレーションに必要なプラクティス

- トランクベース開発は非常に重要ではあるが、実際に導入するには以下のようなプラクティスが必要

#### 1.信頼できる高速な自動テスト

- 継続的インテグレーションの重要なプラクティスに「検証が失敗したら即開発を止めて修正する」というものがある
  - 「常に動く状態を保ち続ける」のが原則であるため
- ただ、トランクベースの開発ではない場合、デプロイされる直前までビルドエラーとかが放置されがち
- 一方、トランクベースの開発の場合は、ある程度これが強制される
  - チェックインしたコードがすぐにデプロイされたり、他の開発者に共有されたりするので、壊れたビルドの影響範囲が大きいため
- また、毎度トランクにコードをマージする時に長いプロセスは実行できないので「高速」であることも大事
- テストの高速化と信頼性向上のための具体的なプラクティス
  - マニュアルテストや結合テストを減らし、ユニットテストの割合を増やす
  - ユニットテストが外部に依存しているようならモックに置き換える
  - 開発者が手元の環境で気軽に検証できるようにする
  - テスト実行する環境を、実行の度に新しい環境(コンテナ)を利用する（並列実行を可能にする）

#### 2.小さいチャンクでの機能開発

- トランクベースの開発では、個々の変更の独立性も重要
  - 別のブランチでの改修が依存関係にあると、トランクの頻繁な更新ができなくなってしまう
- この観点で参考にできるのが「INVEST」という考え方
  - 良いプロダクトバックログアイテム(PBI)を作るための基準になるもの
  - 小さく、独立性があり、テスト可能であることが大事
  - 小さな単位でコード変更を行い、リリースできる状態を保ちながらマージを続ける

#### 3.デプロイとリリースの分離

- いつ、どのようにリリースするかというのは複雑な要件が入り乱れていることがある
  - プレスリリースやベータ版とか
- この時にコードがマージされたらすぐにリリースされるのを避けるため、featureブランチにコードを退避したりする
  - この状態は健全ではない
- 複雑なリリース要件を満たしながら、継続的インテグレーションを実施するには、デプロイとリリースを分離する必要がある
- そこで利用される技術が「Continuous Configuration(CC)」になる
- Continuous Configuration(CC)
  - 機能フラグを用いて、リリースしたいコードを制御する
- リリースブランチ
  - メインのブランチが高品質に保たれていても、実際のリリースプロセスに時間を要することがある
    - 例：専任チームによる検証が必須とか
  - リリースブランチを導入することで、継続的インテグレーションを導入しつつ、リリースの安定化のための時間を確保できる
  - 開発チームはトランクベースで開発しつつ、リリースプロセスはリリースブランチで運用するイメージ
- 継続的デリバリー
  - そもそも継続的デリバリーとは？
    - コード変更が発生すると、自動的に実稼働環境へのリリース準備が実行されるもの
  - これを実現するためには、トランクベース開発と継続的インテグレーションを前提にコードベースを信頼できる状態に保ち、デプロイを安全に行えるようにする必要がある

#### ここまで一言でまとめると..
- トランクベースで小さく開発を進め、ユニットテストを充実＆高速化＆自動化し、CI/CDパイプラインを構築(活用)して、分離されたデプロイ＆リリースプロセスを高速に回していこう

### 小規模かつ可逆的な変更を頻繁に行うためのアーキテクチャパターン

#### Continuous Configuration(CC)によるリリース管理

- Amazonのプライムデーでは、開催と同時にコードを変更しているわけではなく、AppConfigを用いて動的にアプリケーションの挙動を変更している
- AppConfigを利用すると、機能フラグの動的な設定を実現できる
- AppConfigの仕組み
  - 公式のエージェントが用意されている
  - それをアプリケーションサーバーに導入する
  - キャッシュやポーリング間隔を設定する
  - アプリケーションからは、ローカルで動いているエージェントから値を取得するだけ(なのでパフォーマンスにも影響なさそう)
- 少しずつデプロイするクライアントを増やしていくなどのデプロイ戦略も可能
- ただし、機能フラグはロジックに余計なif文が混ざり可読性を落としてしまうのと、フラグの誤操作により障害発生などのリスクもある
  - なので、短期的なフラグとしてマーク（コードコメント等）して、定期的にクリーンアップするのが大事
  - 機能フラグを追加した時点で、削除するというバックログも追加するなどの工夫をする


#### 抽象化によるブランチ

- 機能フラグと同様に、時間のかかる変更を小さなチャンクで実施する技法の1つ
- 機能フラグは新規機能等では有用であるが、例えばORマッパを変更したいなどの既存機能に大きく影響する箇所はどうすれば良いか
- そこで活躍するのが「抽象化によるブランチ」にある
- 例えば、メール送信機能を同期処理からSQS*Lambdaの非同期処理にしたいケース
  - 実装を特定し、
  - その実装を含む抽象化レイヤを作成する
  - 既存実装を抽象化レイヤの呼び出しに変更する
  - 抽象化レイヤで機能フラグを用いて、一部を新しい実装に切り替える
  - これを完全に置き換えるまで少しづつ続ける
- つまり、
  - 呼び出し側は抽象化されたインターフェイスを呼び出すだけ  
  - そのインターフェイスの実装側で機能フラグにより新旧処理を呼び分ける
- このパターンはステップが多く開発オーバーヘッドがかかるので、呼び出し箇所が多いPRマッパの変更や基盤技術の変更等で有用

## 4章 セキュリティを作り込む

### 責任共有モデルとセキュリティ

- セキュリティにおいても、最も重要なことは責任共有モデルを意識すること
- なるべくクラウド提供者の責任範囲を大きくするようにアーキテクチャを選択することで、セキュリティ対策にかける時間とコストを抑えることが重要

### 疎結合なアプリケーションのセキュリティ

- コンポーネントの中のセキュリティを考え、そしてコンポーネント間のセキュリティ（どのようなデータが送受信され、どのような権限が設定されているか）を考える
- LambdaとSQSを用いたイベント駆動アプリケーションの例
  - それぞれのリソースにアクセスできるリソースを権限で絞る
  - Lambda関数のコードをセキュリティを考える
    - Amazon Inspectorで脆弱性がないかスキャンしたり、コードに署名することで改竄されていないことを保証したりできる
- 全体を俯瞰しながら、どの部分にどのようなセキュリティ対策が必要かを体系的に実施できるのが「脅威モデリング」と呼ばれる手法

### 脅威モデリング

- 対象のシステムにどのような悪いことが起き、どのように対処すべきを明確にするための構造化された手法
- AWSでは、脅威モデリングの実施を、セキュリティに関するベストプラクティスの1つとして紹介している
- 実施頻度
  - 新規の設計や既存の設計変更など定期的に
  - 設計段階から、セキュリティ上の課題を特定できるのが大きなメリット

## 5章 DevOpsとプラットフォームエンジニアリング

- DevOpsは、開発チームと運用チームが責任を共有しコラボレーションできる文化

### クラウドネイティブなチームモデル

- クラウドネイティブな開発で求められるチーム
  - 価値のあるサービスの設計〜開発〜デプロイ〜運用まで関わるビジネスのドメインに関わるチーム
  - そのチームの負荷を軽減するためのチーム
- (個人メモ)よくプロダクト開発チームとプラットフォーム/イネイブルチームみたいな構成があるが、これがそれを体現しているもの
  - このチーム構成で運用している開発組織はDevOpsを意識している（できているかはともかく）と理解できる

# 第2部 回復力を高める

## 6章 スケーラブルなアーキテクチャを実装する

### オートスケーリングを前提としたアプリケーション構造

- サーバーに依存しないセッション管理
  - スティッキーセッションという解決法
    - ユーザーは常に同じサーバーにルーティングされるので、負荷分散できず微妙
  - ここで出るのがデータストアでのセッション管理

### データベースの負荷をコントロールする

- オートスケーリングを行う場合に気をつけるべきなのがデータベースへの負荷のコントロール
- RDBMSを利用する場合は、リソースを有効活用するためにコネクションプーリングを使用する
- コネクションプーリングには、大きく分けて以下の2種類がある
  - JDBCのようなローカル変数を使ったドライバ形式
  - Pgpoolのようなプロキシ形式
    - 多くのアプリケーションでは言語フレームワークとセットでドライバ形式を利用することが多いと思われる
- 使い分けとしては、
  - EC2のようなオートスケールを能動的に指定する場合：ドライバ型（コネクション数を計算がしやすく、管理の見落としが少ない）
  - Lambdaのような負荷に応じて自動でリソースがスケールする場合：プロキシ形式
    - ドライバ型は環境変数を使用するため、意図せずRDBMS側の消費してしまうリスクが発生する 
    - このようなリスクを低減するため、Lambdaとデータベースの間にプロキシ形式のコネクションプール層を設けると良い(RDS Proxyとか)
- 他にオートスケーリングするアプリケーションでデータベース側の負荷を低減する方法としては、リードレプリカの活用がある
  - 読み取り処理をリードレプリカに向けることで、プライマリへの負荷を低減できる

### アプリケーションを適切に分解する

- モノリス構造だと、1つのアプリケーションとして複数の機能が提供されており、負荷が上がりスケールアウトした時に、全体では通常通りの性能に見えても、特定の機能の性能が劣化しているということがある
  - このような事態になったときに、アプリケーションの分割を検討する
- アプリケーションを分割すると、オートスケールによる性能向上もピンポイントで行える
  - 一方、分割することで管理コストが上がったり、整合性担保が難しくなるケースもあるので、むやみやたらに分割することは推奨しない

### スケールインにおいて考慮すること

- 増やした台数を減らすスケールインも重要
- アプリケーションがステートレスで作られていれば、スケールインは容易
- ただし、処理の途中経過やセッションをサーバー内で保持していると、処理の中断を防ぐため以下のような仕組みを用いて、データ待避や保存が必要になる
  1. 終了ポリシー
    - スケールイン時に終了するインスタンスをどのような基準で選ぶかを定義する
    - 最も古い/新しい/低負荷なインスタンスを終了するというようなルールを設定する
      - AWS Auto Scalingでは、OldestInstanceポリシー等が用意されている
      - [Amazon EC2 Auto Scaling の終了ポリシーを設定する - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/ja_jp/autoscaling/ec2/userguide/ec2-auto-scaling-termination-policies.html)
  2. スケールイン保護
    - 処理が動いているサーバーを停止しない仕組み
    - 何らかのメトリクス(例:CPU使用率やカスタムメトリクス（例: 処理中ジョブ数）)をもとにスケールインイベントを設定した際、閾値を下回ると自動的にリソースを停止する
    - ECSにもそのような仕組みがあるみたい
      - [Amazon ECS タスクのスケールイン保護の発表 | Amazon Web Services ブログ](https://aws.amazon.com/jp/blogs/news/announcing-amazon-ecs-task-scale-in-protection/)
  3. 終了ライフサイクルフック
    - インスタンス開始・終了時にプログラムなどを起動する仕組み
    - これをトリガーにして、稼働中のプログラムに終了処理を行わせることが可能
    - 例えば、セッションデータやログをS3などの外部に保存するようにしたり、メッセージキューに通知したり、ロードバランサーからの登録を解除したり..

### 非同期アーキテクチャによるスケーラビリティ

- スケーリングの仕組みを活かすのに非同期処理を前提にするというのも選択肢になる
- 同期処理だと、負荷上昇時に滞留が増えてしまう
- 同期処理が必須ではない部分は、非同期処理の活用がおすすめ
- 受付と処理を分離できるので、ユーザーに対する応答性及び処理能力の改善が見込まれる

非同期処理の実装方法を4つ紹介する

#### 非同期処理実装パターン1: キュー(SQS)

- 一時的にメッセージを格納する軽量バッファと接続エンドポイントを提供することで、メッセージの送信側(プロデューサー)と受信側(コンシューマ)を分離する
- 受信側のタイミングでキューを取りに行き処理する「Pull型」のアプローチとなる
- 1対1
- メッセージは1回処理される
- ユースケース
  - ジョブキュー: バッチ処理や画像変換タスク
    - 例:ジョブをキューに貯めて、x分間に1度バッチ処理を行う
  - 支払い処理システムのトランザクション処理

#### 非同期処理実装パターン2: トピック(SNS)

- 通信チャネルとして機能する論理アクセスポイントを提供することで、送信側(Publisher)からのメッセージを登録(Subscribe)する複数の受信者に発行する「pub/subメッセージング」を主体とした考え方
- キューと違い、発行されたメッセージが受信側に届く「Push型」のアプローチ
- 1対多
- Subscriberごとにメッセージが複製される
- ユースケース
  - マイクロサービス間の通知配信
  - システム監視アラート

#### 非同期処理実装パターン3: ストリーム(Amazon Kinesis Data Stream)

- ストリームは、データソースによって継続的に生成されるデータを低レイテンシーに取り扱うための考え方
- 以下の2つのレイヤで構成される
  - レコードの並び替えや高速な読み書き、整合性をサポートするストレージレイヤ
  - そのデータを計算し不要になったデータを削除する処理レイヤ
- 1対多
- ユースケース
  - リアルタイムログ処理
    - アクセスログ分析
  - データパイプライン構築
    - ETL処理

#### 非同期処理実装パターン4: イベントバス(EventBridge)

- イベントバスは、キューやトピックを使った応用的な手法。
  - 送信側からのイベントやメッセージを受信するパイプラインにより、事前に定義されたルール条件に一致するかチェックし、該当する受信者にルーティングする
- イベント駆動型アーキテクチャの中核となる
- フィルタリングやルーティングの柔軟性が高い
- ユースケース
  - サーバレスアプリケーションでのイベント連携
    - Lambdaのトリガー
  - CloudWatchからEventBridgeでイベントを受信し、ルールに基づいてLambda等に転送する

### 非同期処理のポイント

- チケット購入手続き処理における、完了後のメール送信などを非同期にする
  - メール配信に処理や障害が発生しても、購入自体は影響受けずに業務を続けられる
  - 加えて、非同期処理にキューを使うことで、後続の処理をスケールアウトしやすくなる

### 非同期処理での整合性担保

- 非同期処理には、障害や遅延の極小化やスケーリングの観点でメリットがある一方、しばしば整合性における課題が挙げられる
  - 上で書いた例だと、購入はできたけど、購入完了メールが配信されないみたいなケース
- 非同期処理システムでは「結果整合性」という考え方が重要になる
  - 一時的には不整合が発生しても、最終的には一貫性のある状態になるということ

### 制限をコントロールする

- いくらリソースをスケーリングできるといっても予算は有限だし、意図しないリソース消費も避けなければいけない

#### クォータ管理を自動化する

-  AWSアカウントには、AWSのサービスごとにデフォルトの「クォータ」というリソース作成上限がある
   - 特定の利用者が大量にリソースを使うことを防いで全体の可用性を保証することと、利用者が意図せず大量リソースを使うことを防止する意図がある
- 一部のクォータに関してはAWS Service Quotasというサービスで管理可能
- クォータの上限に近づいているかは、AWS Trusted Advisorでも確認可能
- 設計や定期的に確認することも大事だが、↑のサービスを利用し、自動化の仕組みを取り入れることもできる

#### アプリケーションの流量制限

- 私たちが管理するアプリケーションでもスケーラビリティにも限界があるので同じことが言える
- 流量制限、つまりレートリミットやスロットリングを設計上意識することが重要
- チケットストアを例にすると、予約開始時間に過負荷が予想される
- 静的資材はCDNを使って配信する
- 動的コンテンツを配信するAPIは、スロットリングやレートリミットを導入し、429(Too Many Requests)を返し、フロントエンド側で適切にハンドリングする等の対策を行う

### アーキテクチャパターン

- EC2でのオートスケーリング
- ECSでのオートスケーリング
  - EC2 on ECSだとホスト側のスケーリングも意識する必要がある
  - Fargateだとサーバーレスのようにホスト側を意識する必要はない
- Lambdaでのオートスケーリング
  - Lambdaは負荷に応じて自動でスケーリングする
  - CloudWatch Logsともネイティブに統合されているので、EC2のように設計上意識する必要はない
  - Lambdaは単なるサーバーの置き換えでの利用は推奨されない
    - モノリシックな構造では、パッケージサイズが大きくなり、起動時間が伸びてしまう
    - そもそも既存のミドルウェアやソースコードが流用できないこともままあるので、その対応も必要になる
  - なので、サーバーレスの恩恵を受けるには小さなコード単位で移行することが重要
    - ただ整合性担保のケアが必要になる等のデメリットもあるので、アプリケーション観点においても分割の是非等を検討することが必要
  - 有効な選択肢
    - Lambda Web Adapter
      - AWS Lambda を利用して従来のウェブアプリケーションをサーバーレス環境にデプロイするためのツール
      - Lambda Web Adapter は、HTTPリクエストをLambda関数に渡し、レスポンスを戻すプロキシとして機能する
      - ExpressやSpring Bootで実装されたアプリケーションをそのまま動作させることができる
      - [Lambda Web Adapter でウェブアプリを (ほぼ) そのままサーバーレス化する Lambda Web Adapter](https://aws.amazon.com/jp/builders-flash/202301/lambda-web-adapter/)を少し読んでみる
        - Dockerfileに1行を追加するだけで、ECSでもLambdaでも動作するコンテナイメージを作ることができる
        - 内部的な仕組みとしては、
          - Lambdaランタイムは/opt/extensions/ディレクトリを確認し、ファイルがあればLambda Extensionとして実行される
          - Lambda ExtensionとしてWeb Adapterが機能し、受信したイベントをパースしてHTTPリクエストに変換し、ウェブアプリのプロセスにHTTPとして転送する(レスポンスも同じ考え方で実行される)
    - Stranglerパターン
      - 既存のシステムやモノリシックアプリケーションを徐々に新しいアーキテクチャやシステムに移行する際に利用されるソフトウェア移行手法

### 結果整合性を担保する3つのパターン

#### 1.サガオーケストレーション

- 非同期処理のアプリケーション障害に対して、前の状態に戻すための逆方向のロジックを実行する「補償トランザククション」を発行し、フォワードリカバリする
- サガパターンには以下の2つのバリエーションがある
  - コレオグラフィ
    - 全体作業を制御する指揮者は存在しない
    - それぞれのサービスがあらかじめ与えられた動作条件に従ってサービスを実行する
    - 後述のファンアウトがこれに該当する
  - オーケストレーション
    - オーケストレーターが処理順序を管理する非同期処理の実装方法
    - 呼び出される側は、順番などを意識しなくて良いので疎結合になる一方、オーケストレーターが単一障害点になるリスクもある

#### 2.トランザクション・アウトボックス

- 例えば、購入履歴テーブルへの書き込みの他に同じトランザクション内でアウトボックステーブルに書き込みを行う
  - 書き込み後にSQSキューへの送信に失敗した場合、書き込みを取り消す処理を実行する必要がある
- トランザクション・アウトボックスでは、イベント処理のロジックがアウトボックステーブルを読み込み、SQSに格納する
- Change Data Captureを活用することもできる
  - DynamoDBアイテムレベルの変更をストリームとして配信する機能があるのでそれを活用する

#### 3.SNSを利用した非同期処理のファンアウト

- トピックを使った非同期処理パターン
- 非同期の並行処理をしていて、そこに新たな処理を追加する場合、プロデューサー側のロジックを変更し、新たにSQSへの書き込み処理などを追加する必要がある
- 「ファンアウト」では、プロデューサーとコンシューマーの間にSNSトピックをかますことで、
  - プロデューサーは、メッセージを発行するだけ
  - コンシューマーは、トピックをサブスクライブするだけ
- という構造にできるので、コンシューマー側はサブスクライブだけで並列処理を追加することができる

### 制限をコントロールするためのパターン

#### 1.CloudFrontFunctionsを活用したVirtualWaitingRoomの実装

- 高負荷時に有料ユーザーのみ優先的にアクセスさせたいみたいなケース
- CloudFront FunctionsでCookieの値に応じて、無料ユーザーのみパスを書き換えて静的なリソースへ誘導することで実現できる
- この方法では、ランダムや先着順で振り分けにも応用できる
- また、障害発生時など一時的にトラフィックを逃がしたい時、ドメインを書き換えるみたいなこともできる

#### 2.AmazonCloudWatchによるクォータ監視と自動化

- [CloudWatchにクォータが統合されたAWSサービス](https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/monitoring/CloudWatch-Quotas-Visualize-Alarms.html)では、CloudWatchのグラフやダッシュボードを作成しての可視化や、アラーム経由での通知や自動化が可能

#### 3.ServiceQuotasAPIを介したクォータ監視

- ServiceQuotasのListServices APIで一覧を取得し、DynamoDBと連携する

## 7章 障害からの自動的な復旧を実現する

- 利用者が設計・担保する責任範囲を狭べることは、障害の可能性を減らすためのアプローチの1つ
- ただ障害が発生しないシステムを構築することは不可能

### リカバリ目標を定義する

- 闇雲に目標を設定するのではなく、目標復旧時間（RTO）と目標復旧時間（RPO）を定めた上で、具体的な実装に落とし込む
- 目標復旧時間（RTO）
  - サービスの中断から復旧までの最大許容遅延
- 目標復旧時間（RPO）
  - 最後のデータ復旧ポイントからの最大許容時間
- 無闇に目標値を高くしてしまうと、コストや難易度という代償がある
- アプリケーション全体ではなく、対象を特定の機能にしたり、目標復旧レベル（RLO）を定めて、どの業務をどの水準までという考え方を併せ持つと良い

### フェイルオーバーを実装する

- 待機系に自動で切り替えを行うフェイルオーバーと言っても、想定する障害やRTO・RPO・RLOに応じて、さまざまな方法から選択する必要がある
- Route53フェイルオーバー
  - ドメイン名を変えずに、リクエストの受け先を変更する
  - リージョン間フェイルオーバーなど、アプリケーション全体の切り替えに使われる
- ELBフェイルオーバー
  - 後続のサーバー等の障害を検知した際に、むき先を変更したり、対象リソースを切り離したりする
- マネージド型サービス機能によるフェイルオーバー
  - AWSの責任範疇の機能としてフェイルオーバーの仕組みが設けたサービスが多い
  - AuroraでマルチAZ構成の場合、障害時はリーダーインスタンスがプライマリインスタンスに昇格する設定が可能
  - Lambdaのようなリージョンに紐づくマネージドサービスの場合は、ユーザーが意識されることなくフェイルオーバーが実施される
- この辺りの設計で意識すべきことは、
  - 採用するサービスがそれぞれどの地理的範囲に紐づくのか
    - リージョンサービスなら、多くはフェイルオーバーしなくて良いという意味
  - マネージドサービスとして、フェイルオーバーの仕組みを設けられているか
  - 自身が管理するアプリケーションのRTOやRPOはどのような値か

### タイムアウト・リトライを実装する

- インフラ側に適切な設定がされていても、アプリケーション側が適切にハンドリングし、利用者に影響がないようにする
  - これを怠ると、一部の問題が全体に広がってしまう「カスケード障害」を引き起こす

#### タイムアウト

- タイムアウト時間は、許容できる失敗率を元にパーセンタイルを設定し、実際のトランザクションのレイテンシーメトリクスに照らし合わせて設定する
- 注意するポイントとしては、
  - インターネット経由で通信する処理があると、処理時間が安定しないことが多い
  - 安定的にレイテンシが短い処理（例：50パーセンタイルと95パーセンタイルでほぼ差がない）だと、通常時のレイテンシを元に設定すると、少しの遅延でもタイムアウトが頻発してしまう
- このようなケースを踏まえて、実測値から随時設定を見直していくのが良い

#### リトライとバックオフ

- エラー後の挙動としてリトライの仕組みを設けると、リトライは各クライアントが利己的（他を気にしないでという意味）に行うので、障害や遅延の長期化になる可能性がある
- なので、リトライの際には、バックオフ（待機時間）を設けることが大事
- バックオフには、以下の方法がある
  - 固定の秒数を加算する
  - 指数関数的に秒数を増やすエクスポネンシャルバックオフ
    - [リトライ処理の効率的アプローチ「Exponential Backoff」の概要とGoによる実装 #Go - Qiita](https://qiita.com/po3rin/items/c80dea298f16a2625dbe)

#### ジッター

- バックオフにランダム性を追加するのがジッターという考え方
  - バックオフは規則性があり、多くの場合は上限値を設ける
  - 障害が長期化した時に、多くのトランザクションが上限値の秒数でリトライを行うことになってしまい、障害の原因が過負荷であった場合に機能しなくなってしまう

#### StepFunctionsによるリトライ機能

- StepFunctionsには、リトライ時のバックオフやジッターが機能として設けられている

#### サーキットブレーカー

- サーキットブレーカーは、エラーの閾値を設けて、それを超えたら呼び出しを一時的に遮断する
  - 特に外部に公開しているAPIだと、クライアントからリトライを制御できない
  - リトライ増加によるトラフィック増に繋がり、過負荷によるカスケード障害を引き起こすことがある
- 言語フレームワーク機能を使って実装したり、サービスメッシュを使ってアーキテクチャとして組み込む方法がある
- サービスメッシュは、マイクロサービスのような互いに呼び出しあう構造にアーキテクチャにおいて有効な手法で、サービス間のすべての通信を処理するソフトウェアレイヤのこと
  - マイクロサービスの前段に、通信のモニタリング・ログ記録・トレース・トラフィックコントロールなどの機能を持つコンテナを配置し、サービス間の通信を管理する
- [mercari.go #12 go-circuitbreakerのご紹介 - Speaker Deck](https://speakerdeck.com/matope/mercari-dot-go-number-12-go-circuitbreakerfalsegoshao-jie?slide=22)

### 安全なデプロイメント

- 障害は、デプロイのようなシステム変更作業時に混入してしまうことも多い

#### ワンボックスデプロイとローリングアップデート

- 主に下位互換の確認のために取られる手法
- 最新のコードを1つのボックス(コンテナなVM)にデプロイして他のバージョンと共存させ問題がでないかを確認する
- 問題が出なかった場合は、段階的にローリングデプロイを行う
  - 段階的: 25％ずつなど割合を決めるのが一般的

#### 時差デプロイ

- 複数のリージョンで展開している場合、いくつかのウェーブに分けて段階的にデプロイを行う
- 応用として、AZやテナントごとにデプロイを徐々に行う方法もある

#### ブルーグリーンデプロイメント

- 2つの同一環境を構築し、トラフィックを切り替える手法
- ロールバックが必要になったら、ブルー環境を再昇格すれば良いので時間短縮のメリットがある

#### フェーズデプロイ

- ここまではインフラメインだったが、アプリケーションの中身の話
- 例えば、あるAPIでのリクエストレスポンスをXML形式からJSON形式に変更する例
  - 仮に、リクエストレスポンスを同時にJSONに変えたバージョンをリリースすると、呼び出し側も変更する必要があり、リスクが高まる
    - ロールバックの際、呼び出し側の考慮も必要になる

#### ロールバックとベイクタイム

- システム停止だけでなく、性能劣化もロールバックの対象になる
- そのためにはメトリクスを取得し、閾値を超えた場合に自動で切り戻せる仕組みが重要
- 上記の判断を行うために重要なのがベイクタイムという考え方
- ベイクタイムというのは、リリース後に一定時間監視し続ける時間
- ECSローリングアップデート機能や、AppConfigのようなデプロイ支援サービスにも、このベイクタイムを設定し、ロールバックする仕組みが設けられている

### アーキテクチャパターン

- 障害からの自動的な復旧を実現するためのアーキテクチャパターンを紹介する

#### フェイルオーバーのためのパターン

- Route53を使った静的安定なリージョンフェイルオーバー
  - ヘルスチェックに失敗したら、セカンダリにフェイルオーバーする
- Standby Takes Over Primary(STOP)

(実務で求められる可用性の域を超えている感じがするため省略)

## 8章 回復力をテストする

- スケーラビリティをテストする
  - IaC化しておくことで柔軟にテスト用環境を作ることができる
- 障害復旧のテストをする
  - FISを使うことでサーバーの強制停止やネットワーク疎通障害をシュミレートできる
  - ターゲットに対し、どのような障害を起こすかを指定でき、結構使えそう
  - [耐障害性テストツール – AWS フォールトインジェクション Service – AWS](https://aws.amazon.com/jp/fis/)

# 第3部 可観測性を高める

- 可観測性とは「システムの内部で何が起きているかを説明できるシステムの状態」のこと
- なぜこのような新しい概念が必要になったか？
  - システム面においては、クラウドネイティブにおける疎結合なアーキテクチャにおいても原因特定を容易できるようにするため
    - 従来のリアクティブなモニタリングでは事足りなくなった
  - ビジネス面においても、そもそもITサービスがビジネスにおいて重要な立ち位置になった＋アクセス数などがビジネス目標立てられるようになったことで、可観測性高く様々なデータを収集できることが重要になった
- 優れた可観測性が、事実に基づいたデータを元にデバッグやトラブルシューティングを可能にし、運用の手間や時間を削減する
  - こうなることで、ビジネスの本質的な部分に時間を割くことを可能にする
- 可観測性の真の目的は「ビジネスの成功」

## 9章 可観測性を実装し運用する

- 可観測性の3本柱
  - ログ
  - メトリクス
  - トレース
    - ある1つのリクエストからレスポンスまでを1つのサービスマップとして可視化できる
- 開発初期フェーズから実装すべき
  - 途中からだと難易度が上がるのと、優先度が下がりやすい
- モニタリングの指標
  - SLI(ServiceLevelIndicator)
    - 稼働状況を数値化した指標。エラー率や応答時間など。
  - SLO(ServiceLevelObjective)
    - サービスレベル目標。SLIの運用目標値。これを定めることでシステムのサービスレベルを定義する。
  - SLA(ServiceLevelAgreement)
    - サービスレベル合意。SLOを達成した場合、未達であった場合の規約。返金します、とか。
- パーセンタイルとは？
  - APIの応答時間の健全性によく利用される統計量のこと
  - 指定した期間の小さい順から大きい順に並べた時に、指定した割合がある値を意味する
  - 平均値より外れ値の影響を受けづらく、中央値と比べて影響を受けるユーザーやリクエストが多い障害を検知しやすいというメリットがある
- エラーバジェット
  - 新機能を早く出したいというビジネス観点と機能追加によってユーザーに悪影響を及ぼすことを避けたいというシステム観点（対立関係）
  - 仮に軽微なエラーなら許容するし、そうでないなら..みたいなもの衝突を、定量的なデータとして管理するための考え方が「エラーバジェット」
  - 小さいミスを許容する代わりに、リリースのアジリティを向上させる
  - 具体的には、定義したSLOの範囲に収まっている間は新機能をリリースし、下回ったりしたら品質改善に注力するみたいな
- 100%のSLOを目指すべきなのか？
  - 過剰品質は、ビジネスの加速を阻害する
  - 品質を求めることで、システムにかかる原価が上がり、利用者数減につながる場合もある
  - SLOは、ビジネス部門を含めて定期的に見直すべき
- トリアージ
  - 優先度付けの意味
  - 全てのアラートを通知し、オオカミ少年状態になってしまうみたいなことを避けるべし
- ビジネスKPIとモニタリング活用
  - KPIを元にモニタリングを設計する
  - ただし、会員数などのリアルタイムで収集しなくても良いデータに関しては、月次レポート・ダッシュボードなどで対応するとよい
- エンドユーザーの体験をモニタリングする
  - システムのメトリクスを収集しても、それが実際どのようにユーザーに影響しているかはわからない
  - ユーザーから見たパフォーマンスをモニタリングする手法として以下がある
    - SyntheticsMonitoring
      - 外形監視。擬似アクセスを発生させモニタリングする。
    - RUM(RealUserMonitoring)
      - 実際のユーザーアクセスを用いてモニタリングする。
- FinOps
  - 財務*DevOps
  - 目的は、クラウドコストの最適化ではなく、その先にあるビジネス価値の最大化である

#### アーキテクチャパターン

- 可観測性を実現するアーキテクチャパターンの紹介
- CloudWatch Application Signals
  - 有効にすると、アプリケーションのテレメトリデータを自動収集し、アクセス数・可用性・レイテンシ・障害・エラーなどの主要メトリクスや、SLOの状況をダッシュボードで可視化できる
- CloudWatch Synthetics
  - ヘッドレスブラウザが対象URLにアクセスする
- CloudWatch RUM
  - 実際のユーザーのセッションを利用して、読み込み時間やクライアントエラー、ユーザーのブラウザやデバイスを可視化できる
- いかに収集したデータを運用するか
  - DevOps Guruなど、AIを活用したサービスもいくつかある(省略)

## 第10章 AWSのサービスを活用してテレメトリを収集する

- X-Rayによる分散トレーシング
- ログ出力先を抽象化する
  - 標準出力に集約し、その標準出力は仮想マシンや外部のログルーターに即時転送するようにする「ログルーター」という実装がある
  - Lambdaのようなサーバーレスアーキテクチャであれば、標準出力するだけでCloudWatch Logsにログを連携できる