# データ指向アプリケーションデザイン

# 第1部 データシステムの基礎

## 1章 信頼性、スケーラビリティ、メンテナンス性に優れたアプリケーション

- 今日のアプリケーションは演算指向ではなくデータ指向
- どのツールやアプローチが目の前のタスクに対して適切か？を判断する必要がある
- それらの使う方法を辿っていくのが本書である
- 本書で焦点を当てるソフトウェアシステムにおける重要な課題3つ
  - 信頼性
    - 障害があっても正しく動作し続ける
  - スケーラビリティ
    - システムの成長（データやトラフィック量・複雑さ）に対して、無理のない方法で対応可能である
  - メンテナンス性
    - 時間が経つにつれ関わる人が多くなっても、生産的に関われる

### 信頼性

- ハードウェアの障害
  - 冗長化することで、ダウンタイムなしのローリングアップデートもできるようになる
- ソフトウェアのエラー
  - システマティックなエラーは、ハードウェア障害と比べると影響範囲が大きくなりがち
  - 手っ取り早い解決策はないので、プロセス分離やテストの徹底をやるしかない
- ヒューマンエラー
  - サービスの障害で最も多いのはオペレータによる設定ミス
  - できることとしては、
    - サンドボックス環境を用意する
    - テストの徹底
    - ロールバックを即座にできるようにしておく
    - パフォーマンスやメトリクスなどをモニタリング

### スケーラビリティ

- システムの劣化の原因の一つとして負荷の増大がある
- 一元的ではなく、多角的にスケーラビリティを議論する必要がある
- Twitterの例
  - ツイートされたらグローバルなコレクションに挿入し、タイムラインではDBからそのユーザーがフォローしているユーザーのツイートを全て取得
    - このやり方で、タイムラインのクエリ負荷の追従に苦しむ
  - 各ユーザーのタイムラインようにキャッシュを管理し、ツイートポスト時にこのキャッシュに挿入することで上記の課題を解消した
    - Twitterでは書き込みより読み込みの方が2桁くらい回数が多いので、書き込みの際の処理を多く、読み込みの際の処理を少なくなるようにした
    - だが、このやり方の欠点として、例えば3000万のフォロワーがいるユーザーがポストをすると、3000万回のキャッシュ挿入処理が走るということ
    - これらに対し、Twitterでは「ユーザーごとのフォロワーの分布」や「ツイート頻度」などのパラメータによって、ファンアウトの負荷を決めている
      - ファンアウトとは、「1つの処理やリクエストが複数の下流処理やサービスに分岐して並行に実行される構造やパターン」のこと
    - この逸話には一捻りがあり、大体のユーザーはキャッシュファンアウトだが、極めて多くのフォロワーを持つユーザーのポストは1番目の方法を採用したハイブリッド形式となったらしい
- レイテンシとレスポンスタイム
  - レイテンシ：クライアントからみた値で、リクエストの処理そのものに費やされた時間＋ネットワークやキューイングによる遅延を含む
  - レスポンスタイム：リクエストが処理を待っている期間で、すなわちリクエストの処理そのものに費やされた時間
- レスポンスタイムの測り方
  - 平均値での指標では外れ値に弱く、ユーザー体験を正確に示さない
    - ユーザーにとって重要なのは自分が体験するレスポンスタイムであり、平均は「典型的な体験」を示さない
    - 例えば、ほとんど速いがたまに遅い、ほとんど遅いがたまに極端に速いといったような違いを平均値は隠してしまう
  - ユーザーの典型的な待ち時間を知りたい：中央値(p50)
  - 外れ値の把握：p95やp99
    - 全データのうち、95％・99％がこの値以下になる境界値
    - p95=400msなら、全リクエストのうち95％は400ms以内に終わっているという意味
    - このような大きなパーセンタイルのレスポンス値は「テイルレイテンシ」と言われ、ユーザーのサービス体験に直接的に関係している重要な値
- 負荷への対処としてのスケーラビリティ
  - 1つのアプリケーションをうまくスケールさせることができるアーキテクチャは、どういった処理が頻繁に行われ、どういった処理が稀なのかを推定＝負荷のパラメータの元に構築される

### メンテナンス性

- メンテナンス性を向上させるために「運用性」「単純性」「進化性」の3つの設計原理を意識する

## 2章 データモデルとクエリ言語

- データモデルはソフトウェア開発で最も重要な部分

### リレーショナルモデルとドキュメントモデル

- リレーショナルデータモデルは1970年に提唱され、その後幾つもの対抗馬が出てきたが、汎用性の高さ・対応できるユースケースの広さを引っ提げて、数多くあるサービスで依然使われている
- NoSQLの登場
  - 2010年代に登場
  - 元々はTwitterのハッシュタグとして使われただけのもので、特定の技術を指さないNot Only SQLとして解釈されている
  - NoSQLデータベースが広がった要因
    - 書き込みスループット
    - 特殊なクエリ操作
    - RDBのスキーマ制約からの解放（動的な表現力）
- オブジェクトとリレーショナルのミスマッチ
  - 今日では多くのアプリケーション開発でオブジェクト指向言語で書かれており、それがSQLデータモデルへの批判に繋がっている
  - コード内のオブジェクトと、テーブル・行・列といったデータモデルとの間に不恰好なデータ変換が必要になってしまう
  - ActiveRecordなどのORMは定型コードの量を減らしてはくれるが完全になくなるわけではない
    - このミスマッチを「インピーダンスミスマッチ」という
  - 履歴書をデータモデルとして表現する例
    - JSONで表現することで、インピーダンスミスマッチを低減すると感じられるかも
    - スキーマがないことはしばしば利点として語られることもある
    - 取得時に、複数テーブルの結合などが不要で、1クエリで取得することができる
    - （だがしかし..）多対多や多対1の表現
      - IDで紐づけることによって、データ更新やローカライゼーションなどの管理が楽
      - 複製を排除するのは、データベースにおける正規化の鍵となる考え方
      - しかし正規化は、ドキュメントモデルにはうまく適合しない
      - ドキュメントデータベースは大抵結合の必要がなく、結合のサポートが弱い
        - 結合はアプリケーション側の仕事として行う必要が出てくる
        - 初期フェーズでは結合が不要なドキュメントモデルで十分かもしれないが、アプリケーションに機能が追加されていく中で、データ同士が繋がりを持っていく
          - 例：ただの文字列で管理していた学校や会社がエンティティ化される
- ドキュメントデータベースは歴史を繰り返すのか？
  - ドキュメントデータベースは多対多の関係を扱うのが難しいという課題があった
  - この課題・制約を解決したのが「リレーショナルモデル」と「ネットワークモデル」
- ネットワークモデル
  - 初期には多くの支持を集めたが、次第に廃れた
  - 階層モデルが1つだけ親を持つのに対し、ネットワークモデルは複数の親を持つことができる
  - ルートからレコードを辿っていき、目的のレコードを取得する
    - これはテープドライブ的には効率が良いが、ネットワークモデルでは求めるデータへのパスがわかっていないという状況が厄介
- リレーションモデル
  - 上記に対し、リレーションモデルはすべてのデータがオープンに置かれる
  - オプティマイザが、クエリの実行順序やどのインデックスを使うか（先程触れた「パス」と同等のもの）を自動的に決めてくれるので、ほとんどの場合開発者が気にしなくて良い
  - オプティマイザの開発には長年労力が費やされてきたが、一度構築してしまえば、そのデータベースを使うすべてのアプリケーションにメリットをもたらす

### リレーショナルデータベースとドキュメントデータベースの「データモデル」の違い

- ドキュメントデータモデルの特徴
  - 1対多の関係のツリー構造で、一度でツリー全体がロードされる場合はドキュメントデータモデルは向いている
    - 例：記事とそれに紐づくコメント
    - リレーションの場合は、細分化により不必要にアプリケーションコードが複雑になることがある
  - ネストされたアイテムの直接参照
    - 直接参照はできないので、この記事の2番目のコメントのように指定する必要がある
    - だが、ネストが深すぎない限りはこれが問題になることは少ない
  - 結合のサポートが貧弱
    - これが問題になるかはアプリケーション次第
    - ただイベントとその発生時刻を記録するのみの分析用アプリケーションでは多対多の関係が必要になることはないだろう
  - 多対多
    - 例：授業と学生、商品とカテゴリ
    - これを必要とするアプリケーションではドキュメントモデルの魅力は薄れる
    - 非正規化をすることで結合の必要性を下げることができるが、アプリケーションコードで整合性を取るようにする必要がある
    - また、結合はアプリケーションからDBへのリクエストを複数行うことで実現できるが、これはDBで結合を行うよりも低速になり、パフォーマンスも大きく低下する
    - 結論、**データ間の関係性が強い場合はドキュメントモデルは扱いにくい**
- ドキュメントデータモデルのスキーマの柔軟性
  - 多くのドキュメントデータベースやリレーションデータベースにおけるJSONサポートは、ドキュメント内のデータに対してスキーマを強制しない
  - ドキュメントデータベースはしばしばスキーマレスと言われるがそれは誤解を招く表現で、なぜならデータを読み取るコードは何らかの構造があることを前提としているため
    - すなわち暗黙のうちにスキーマがあることを想定しているが、DBがそれを強制しないということ
  - これが大きく影響するのが「スキーマ変更」
    - 例えばフルネームで入っている所を姓と名で分けたいケースを想定する
    - ドキュメントデータベースの場合は、アプリケーションコード側で姓名がない場合は新たにドキュメントに保存するようにするだけ
    - リレーションデータベースの場合は、スキーマ変更（ALTER TABLE）とマイグレーションが発生する
      - ALTER TABLE文によるスキーマ変更は、数ミリ秒で処理されるが、MySQLは例外でテーブル全コピーするので、大規模なテーブルの場合は数分から数時間に至るダウンタイムが発生する
        - 一時テーブル作成→一時テーブルに全コピー→インデックス再構築→一時テーブルのテーブル名を変更（全データを読み出して、書き戻すため、テーブルサイズに比例して時間がかかる）
      - UPDATE文の実行は、すべての行を書き直すので、いかなるDBにおいても低速になる
    - ドキュメントデータベース（スキーマオンリード＝読み取り時にスキーマを保証）のアプローチは以下のケースでメリットがある
      - 数多くのドキュメントの種類がある
      - データ構造が外部のシステムによって決定される
        - **すなわち固定のスキーマではない場合にドキュメントデータベースはメリットを発揮する**
- クエリのためのデータローカリティ（局所性）
  - ローカリティというのは、データが物理的・論理的に近接して配置され、アクセス時にまとめて取得できる性質を指す
  - ドキュメントは、テーブル分割等がされていないので、1度のクエリでデータ分割されていないので、パフォーマンス面でメリットがある
    - このメリットが生じるのは、一度にドキュメントの大部分が必要になるケースのみ
  - ドキュメントを更新する時は、通常ドキュメントを全体を書き直さなければいけない（一部だけ更新ができない）
  - なので、ドキュメントは小さく保つことが望ましい