# データ指向アプリケーションデザイン

# 第1部 データシステムの基礎

## 1章 信頼性、スケーラビリティ、メンテナンス性に優れたアプリケーション

- 今日のアプリケーションは演算指向ではなくデータ指向
- どのツールやアプローチが目の前のタスクに対して適切か？を判断する必要がある
- それらの使う方法を辿っていくのが本書である
- 本書で焦点を当てるソフトウェアシステムにおける重要な課題3つ
  - 信頼性
    - 障害があっても正しく動作し続ける
  - スケーラビリティ
    - システムの成長（データやトラフィック量・複雑さ）に対して、無理のない方法で対応可能である
  - メンテナンス性
    - 時間が経つにつれ関わる人が多くなっても、生産的に関われる

### 信頼性

- ハードウェアの障害
  - 冗長化することで、ダウンタイムなしのローリングアップデートもできるようになる
- ソフトウェアのエラー
  - システマティックなエラーは、ハードウェア障害と比べると影響範囲が大きくなりがち
  - 手っ取り早い解決策はないので、プロセス分離やテストの徹底をやるしかない
- ヒューマンエラー
  - サービスの障害で最も多いのはオペレータによる設定ミス
  - できることとしては、
    - サンドボックス環境を用意する
    - テストの徹底
    - ロールバックを即座にできるようにしておく
    - パフォーマンスやメトリクスなどをモニタリング

### スケーラビリティ

- システムの劣化の原因の一つとして負荷の増大がある
- 一元的ではなく、多角的にスケーラビリティを議論する必要がある
- Twitterの例
  - ツイートされたらグローバルなコレクションに挿入し、タイムラインではDBからそのユーザーがフォローしているユーザーのツイートを全て取得
    - このやり方で、タイムラインのクエリ負荷の追従に苦しむ
  - 各ユーザーのタイムラインようにキャッシュを管理し、ツイートポスト時にこのキャッシュに挿入することで上記の課題を解消した
    - Twitterでは書き込みより読み込みの方が2桁くらい回数が多いので、書き込みの際の処理を多く、読み込みの際の処理を少なくなるようにした
    - だが、このやり方の欠点として、例えば3000万のフォロワーがいるユーザーがポストをすると、3000万回のキャッシュ挿入処理が走るということ
    - これらに対し、Twitterでは「ユーザーごとのフォロワーの分布」や「ツイート頻度」などのパラメータによって、ファンアウトの負荷を決めている
      - ファンアウトとは、「1つの処理やリクエストが複数の下流処理やサービスに分岐して並行に実行される構造やパターン」のこと
    - この逸話には一捻りがあり、大体のユーザーはキャッシュファンアウトだが、極めて多くのフォロワーを持つユーザーのポストは1番目の方法を採用したハイブリッド形式となったらしい
- レイテンシとレスポンスタイム
  - レイテンシ：クライアントからみた値で、リクエストの処理そのものに費やされた時間＋ネットワークやキューイングによる遅延を含む
  - レスポンスタイム：リクエストが処理を待っている期間で、すなわちリクエストの処理そのものに費やされた時間
- レスポンスタイムの測り方
  - 平均値での指標では外れ値に弱く、ユーザー体験を正確に示さない
    - ユーザーにとって重要なのは自分が体験するレスポンスタイムであり、平均は「典型的な体験」を示さない
    - 例えば、ほとんど速いがたまに遅い、ほとんど遅いがたまに極端に速いといったような違いを平均値は隠してしまう
  - ユーザーの典型的な待ち時間を知りたい：中央値(p50)
  - 外れ値の把握：p95やp99
    - 全データのうち、95％・99％がこの値以下になる境界値
    - p95=400msなら、全リクエストのうち95％は400ms以内に終わっているという意味
    - このような大きなパーセンタイルのレスポンス値は「テイルレイテンシ」と言われ、ユーザーのサービス体験に直接的に関係している重要な値
- 負荷への対処としてのスケーラビリティ
  - 1つのアプリケーションをうまくスケールさせることができるアーキテクチャは、どういった処理が頻繁に行われ、どういった処理が稀なのかを推定＝負荷のパラメータの元に構築される

### メンテナンス性

- メンテナンス性を向上させるために「運用性」「単純性」「進化性」の3つの設計原理を意識する

## 2章 データモデルとクエリ言語

- データモデルはソフトウェア開発で最も重要な部分

### リレーショナルモデルとドキュメントモデル

- リレーショナルデータモデルは1970年に提唱され、その後幾つもの対抗馬が出てきたが、汎用性の高さ・対応できるユースケースの広さを引っ提げて、数多くあるサービスで依然使われている
- NoSQLの登場
  - 2010年代に登場
  - 元々はTwitterのハッシュタグとして使われただけのもので、特定の技術を指さないNot Only SQLとして解釈されている
  - NoSQLデータベースが広がった要因
    - 書き込みスループット
    - 特殊なクエリ操作
    - RDBのスキーマ制約からの解放（動的な表現力）
- オブジェクトとリレーショナルのミスマッチ
  - 今日では多くのアプリケーション開発でオブジェクト指向言語で書かれており、それがSQLデータモデルへの批判に繋がっている
  - コード内のオブジェクトと、テーブル・行・列といったデータモデルとの間に不恰好なデータ変換が必要になってしまう
  - ActiveRecordなどのORMは定型コードの量を減らしてはくれるが完全になくなるわけではない
    - このミスマッチを「インピーダンスミスマッチ」という
  - 履歴書をデータモデルとして表現する例
    - JSONで表現することで、インピーダンスミスマッチを低減すると感じられるかも
    - スキーマがないことはしばしば利点として語られることもある
    - 取得時に、複数テーブルの結合などが不要で、1クエリで取得することができる
    - （だがしかし..）多対多や多対1の表現
      - IDで紐づけることによって、データ更新やローカライゼーションなどの管理が楽
      - 複製を排除するのは、データベースにおける正規化の鍵となる考え方
      - しかし正規化は、ドキュメントモデルにはうまく適合しない
      - ドキュメントデータベースは大抵結合の必要がなく、結合のサポートが弱い
        - 結合はアプリケーション側の仕事として行う必要が出てくる
        - 初期フェーズでは結合が不要なドキュメントモデルで十分かもしれないが、アプリケーションに機能が追加されていく中で、データ同士が繋がりを持っていく
          - 例：ただの文字列で管理していた学校や会社がエンティティ化される
- ドキュメントデータベースは歴史を繰り返すのか？
  - ドキュメントデータベースは多対多の関係を扱うのが難しいという課題があった
  - この課題・制約を解決したのが「リレーショナルモデル」と「ネットワークモデル」
- ネットワークモデル
  - 初期には多くの支持を集めたが、次第に廃れた
  - 階層モデルが1つだけ親を持つのに対し、ネットワークモデルは複数の親を持つことができる
  - ルートからレコードを辿っていき、目的のレコードを取得する
    - これはテープドライブ的には効率が良いが、ネットワークモデルでは求めるデータへのパスがわかっていないという状況が厄介
- リレーションモデル
  - 上記に対し、リレーションモデルはすべてのデータがオープンに置かれる
  - オプティマイザが、クエリの実行順序やどのインデックスを使うか（先程触れた「パス」と同等のもの）を自動的に決めてくれるので、ほとんどの場合開発者が気にしなくて良い
  - オプティマイザの開発には長年労力が費やされてきたが、一度構築してしまえば、そのデータベースを使うすべてのアプリケーションにメリットをもたらす

### リレーショナルデータベースとドキュメントデータベースの「データモデル」の違い

- ドキュメントデータモデルの特徴
  - 1対多の関係のツリー構造で、一度でツリー全体がロードされる場合はドキュメントデータモデルは向いている
    - 例：記事とそれに紐づくコメント
    - リレーションの場合は、細分化により不必要にアプリケーションコードが複雑になることがある
  - ネストされたアイテムの直接参照
    - 直接参照はできないので、この記事の2番目のコメントのように指定する必要がある
    - だが、ネストが深すぎない限りはこれが問題になることは少ない
  - 結合のサポートが貧弱
    - これが問題になるかはアプリケーション次第
    - ただイベントとその発生時刻を記録するのみの分析用アプリケーションでは多対多の関係が必要になることはないだろう
  - 多対多
    - 例：授業と学生、商品とカテゴリ
    - これを必要とするアプリケーションではドキュメントモデルの魅力は薄れる
    - 非正規化をすることで結合の必要性を下げることができるが、アプリケーションコードで整合性を取るようにする必要がある
    - また、結合はアプリケーションからDBへのリクエストを複数行うことで実現できるが、これはDBで結合を行うよりも低速になり、パフォーマンスも大きく低下する
    - 結論、**データ間の関係性が強い場合はドキュメントモデルは扱いにくい**
- ドキュメントデータモデルのスキーマの柔軟性
  - 多くのドキュメントデータベースやリレーションデータベースにおけるJSONサポートは、ドキュメント内のデータに対してスキーマを強制しない
  - ドキュメントデータベースはしばしばスキーマレスと言われるがそれは誤解を招く表現で、なぜならデータを読み取るコードは何らかの構造があることを前提としているため
    - すなわち暗黙のうちにスキーマがあることを想定しているが、DBがそれを強制しないということ
  - これが大きく影響するのが「スキーマ変更」
    - 例えばフルネームで入っている所を姓と名で分けたいケースを想定する
    - ドキュメントデータベースの場合は、アプリケーションコード側で姓名がない場合は新たにドキュメントに保存するようにするだけ
    - リレーションデータベースの場合は、スキーマ変更（ALTER TABLE）とマイグレーションが発生する
      - ALTER TABLE文によるスキーマ変更は、数ミリ秒で処理されるが、MySQLは例外でテーブル全コピーするので、大規模なテーブルの場合は数分から数時間に至るダウンタイムが発生する
        - 一時テーブル作成→一時テーブルに全コピー→インデックス再構築→一時テーブルのテーブル名を変更（全データを読み出して、書き戻すため、テーブルサイズに比例して時間がかかる）
      - UPDATE文の実行は、すべての行を書き直すので、いかなるDBにおいても低速になる
    - ドキュメントデータベース（スキーマオンリード＝読み取り時にスキーマを保証）のアプローチは以下のケースでメリットがある
      - 数多くのドキュメントの種類がある
      - データ構造が外部のシステムによって決定される
        - **すなわち固定のスキーマではない場合にドキュメントデータベースはメリットを発揮する**
- クエリのためのデータローカリティ（局所性）
  - ローカリティというのは、データが物理的・論理的に近接して配置され、アクセス時にまとめて取得できる性質を指す
  - ドキュメントは、テーブル分割等がされていないので、1度のクエリでデータ分割されていないので、パフォーマンス面でメリットがある
    - このメリットが生じるのは、一度にドキュメントの大部分が必要になるケースのみ
  - ドキュメントを更新する時は、通常ドキュメントを全体を書き直さなければいけない（一部だけ更新ができない）
  - なので、ドキュメントは小さく保つことが望ましい

### データのためのクエリ言語

- SQLは宣言的クエリ言語であるのに対し、IMSやCODASYL(階層型)は命令的コードを使用する
  - SQLが宣言的であるというのは、どのインデックスを使うかどの結合方法を使いなどは指定せず、あくまで求める条件とその変換(集計)方法だけを指定する点
- 宣言的だと、
  - 簡潔で扱いやすい
  - 並列処理に向いている（昨今のCPUはクロックを高速にするのではなくコア数をあげるムーブなのでそれに合っている）
    - 命令的だとその順序通りに処理を進める必要があるが、宣言的だと処理の中身として並列に動かしやすいという話だという雑な理解

### グラフ型のデータモデル

- データ同士の繋がりが複雑になっていくと、データをグラフとしてモデル化するのが自然となる

## 3章 ストレージと抽出

- 最も根源的なレベルでは、データベースがやらなければいけないことは「与えられたデータを保存すること」と「データを要求されたら返すこと」
- 2章では、アプリケーション開発者がデータベースにデータを渡すフォーマットとそれを再び取り出すための仕組みをみてきた
- この3章では、データベース側の観点からみていく
- 開発者はデータベース内部の動きに留意しておくべき
  - なぜならアプリケーションの性質から最適なデータベースを選択できるようにするため

### データベースを駆動するデータ構造

- シェルで書かれたシンプルなKVSスクリプト
  - セットはファイル末尾に追記、ゲットはファイルから取得するだけのシンプルなDB
  - このファイルを「ログ」と呼び、追記だけが行われるレコードを指す
- db_setのパフォーマンスはかなり優れている（ファイルへの追記は非常に効率的な操作であるため）
- 対して、db_getはレコード数が増えるつれ酷いパフォーマンスになる
  - 先頭からルックアップしていくため、計算量はO(n)：レコード数がnの2倍になれば、ルックアップにかかる計算量も2倍になる
  - ここで特定のキーの値を効率よく見つけるために必要なのがインデックス
- インデックスは、メタデータを追加で横に置いておくようなもので、それがデータの場所を知る手掛かりになる
- インデックスは、書き込み時にオーバーヘッドが発生する

### そもそもインデックスとは？(自分で調べたこと)

- 本物のデータとは別に作られる、検索を速くするための補助データ構造
- 基本的には、中身は「キー」と「そのキーがある場所（ポインタ的なもの）」のペア
  - MySQLを例にすると、クラスタ化インデックスは行データの全てが格納される（プライマリインデックス）対して非クラスタ化インデックスは行への参照のみ（セカンダリインデックス）

### ハッシュインデックス

- キーバリュー型のデータのためのインデックス
- KVSは、辞書型のようなもので、ハッシュマップ（ハッシュテーブル）として実装される
  - ハッシュマップとは、キー名にハッシュ値を使用することで、キーから値を効率よく探すことができる
    - Goのmap[key]valueやPythonのdict型などに使われている
    - 元々のキーの値が失われるわけではなく、(キー、値)の組が格納される
  - これがKVSの内部実装に使われている
- オンディスク型のKVSの内部構造
  - メモリにキーとそれに対応するバイトオフセットのマッピングを配置する
    - このバイトオフセットというのは、「何バイト目から値が始まるか」という値
  - 実際の値の取得時は、メモリ上のハッシュマップを調べ、データファイルのXバイト目をシークし、データを返す
  - 計算量としてはO(1)（ファイルシーク1回だけ）であり、メモリに全データ載せなくて良いので省メモリ
- セグメントとコンパクション
  - 1つの大きなファイルに全部追記すると巨大化して管理が難しくなる
  - なので、小さな単位（セグメント）に区切ってログを保存する
  - 追記型ストレージでは古いデータがそのまま残ってしまうので、不要（古いor削除済みなど）を整理してストレージを綺麗にするコンパクションという処理が行われる
- 追記のみを行う設計
  - メリット
    - 追記とマージはシーケンシャルな書き込み処理（末尾に連続的にデータを書き込む）なので、とても高速
      - ランダムアクセスだとヘッドを動かす必要があり、遅くなる
    - 更新がないので、更新時に一部が古い状態になってしまっているというようなことを気にしなくて良い
  - デメリット
    - ハッシュテーブルがメモリから溢れた場合のケアやパフォーマンス懸念
    - 範囲に対するクエリの効率が良くない

### SSTableとLSMツリー

- 上記はキーと値のペアが書き込まれた順に並び、ログの後の方に現れた値はそれより前に存在していた同じキーの値より優先され、それ以外に並び順の意味はない
- このセグメントファイルのキーをソートすると、Sorted String Table(SSTable)と呼ばれる
  - また、ファイルの中には同一キーは一度だけしか存在しない（キーでユニークとなる）という条件も加える（コンパクション）
- これをハッシュインデックスを持つログセグメントと比較すると、
  - マージ処理が効率的
  - メモリ使用量が少ない
    - 特定のキーを探す時、もはやすべてのキーをメモリに保持している必要はない
    - 各ブロックの先頭キーだけインデックスしておき、詳細な位置はディスクをシーケンシャルに読めば良い
      - おおよその位置となるブロック位置を特定し、そこからは順番に読んで探し当てる
- と、メリットばかり触れたが、SSTableの構築（キーごとにソートして保存）はどうすれば良いか？
  - いきなりディスクにソートしながら書くわけではなく、インメモリにデータを溜めてからソートして書き出すという手順を踏む
  - メモリ上に置かれるソート済みのデータ構造はMemTableという
    - MemTableは、入れる時に並び替える
- Log-Structured Merge-Tree(LSMツリー)
  - 上記のログファイルへの追記のみ・ソート済みファイルのマージとコンパクションという原理を基盤とするストレージエンジンをLSMストレージエンジンと呼ばれる
  - 命名の由来としては、
    - Log-Structured = 追記ログのように書く
    - Merge = SSTableをまとめてマージする（コンパクション）
    - Tree = 構造全体が階層的（MemTable + SSTable階層）に管理される
  - LevelDB / RocksDB / Cassandra / HBaseなどで使われている
  - Elasticsearchで使われている全文検索のためのインデックスエンジンであるLuceneも、語の辞書を同様の手法で保存しており、キーバリューインデックスより複雑ではあるが、基盤としての考え方は似ている
    - キーを語、値をその語を含むすべてのドキュメントのIDのリストへのマッピングはSSTableに似たソート済みファイルに保存される
      - 例：`"検索" → [Doc1, Doc3, Doc7]`
    - これらのファイルは、バックグラウンドでマージされる
- パフォーマンスの最適化
  - ブルームフィルタ：
    - LSMツリーアルゴリズムでは、存在しないキーのルックアップに時間がかかる
      - MemTableを調べた後に、最も古いセグメントに至るまですべてのディスクを調べる必要があるため
    - あるキーがデータベースにあるかどうかを効率的に判定するためのデータ構造で、上記の問題を解消する
      - 複数のハッシュ関数を使って、要素をビット配列にマッピングし（これをブルームフィルタ内で保持する）、実際の検索時にも同じハッシュ関数を使い、全ての位置が1なら「含まれるかも」、どれか0なら「絶対に含まれていない」とするもの
      - データが増えれば増えるほど、立つビットは多くなるので、偽陽性が増える
- ここまでの整理
  - log-structuredインデックスというのは、更新は全部追記で行うインデックス構造のこと
    - ランダム書き込みを避けて、ディスクI/Oをシーケンシャルにする設計
    - どういうふうにデータを書き込むかの戦略・設計のこと
  - そしてそのlog-structuredの思想を木構造のインデックスに落とし込んだものが「LSM-Tree」
    - ログ追記のみでは遅いという課題があるので、色々な実装（工夫）で、検索を効率化している
      - コンパクションやMemTable・ブルームフィルタ

### Bツリー

- 上記で説明したlog-structuredインデックスは広く受け入れられているものの、インデックスの種類としては一般的ではない
- 最も広く使われているのが「Bツリー」で、ほとんどのリレーショナルデータベースにおける標準的なインデックス実装
- SSTableと同様にキーと値のペアをキーをソートした状態で保持するので、キーと値のルックアップや範囲のクエリを効率よく処理できる
  - 似ているのはここだけで、設計哲学は大きく異なる
- log-structuredインデックスは可変サイズのセグメントに分割するが、Bツリーは通常4KBの固定サイズのブロック・ページにデータベースを分割する
  - 1つのページがBツリーのルートになる
  - ページには子のページへの参照が含まれている
  - その子ページに、値もしくはその参照が格納されている
- ほとんどのデータベースでは、Bツリーの深さが3 or 4で収まるので、探しているページを見つけるために多くのページ参照を追跡する必要はない
  - ページサイズが4KB・深さが4・分岐計数500(1ページ内の子ページへの参照数)の場合、ツリーは最大256TBを保存できる

#### Bツリーの信頼性を高める

- Bツリーにおける書き込み操作は「上書き」でそのページへの参照はそのまま
  - LSMツリーのようにファイル追記だけを行うログ型の構造とは極めて対照的
- 上書きだとクラッシュした時にBツリーが壊れてしまうリスクがある
- クラッシュへの耐性として、write-aheadログというディスク上の追加の構造化データを持ち、全ての変更内容をツリーそのもののページに反映させる前に書き込む
  - クラッシュ後に回復する際は、このログを使ってBツリーを整合性の取れた状態に回復させる

### BツリーとLSMツリーの比較

- Bツリーは読み取りが速く、LSMツリーは書き込みが速い

#### LSMツリーの利点

- Bツリーインデックスは、
  - 全てのデータを最低でも2回書き込む必要がある（write-aheadログとツリーそのものに）
  - ページ（ブロック）の一部更新だったとしても、ページ全体を書く必要があり、オーバーヘッドがある
    - ディスクからページを読み込み、メモリ上で変更、ページ単位でディスクに書き戻すという流れ
  - ノードは、ディスク上にバラバラに配置されている（ページごとの位置は必ずしも連続していない）ので、ランダムI/Oが発生してしまう
- 一方、LSMツリーの基礎となるlog-structuredインデックスは、
  - まずはメモリ（MemTable）にappendして、メモリがいっぱいになったら、ディスクにSSTableとして書き出すので、シーケンシャルI/O（連続した領域に順番に書き込む）
  - このシーケンシャルな書き込みが、ランダムな書き込みよりも優れているので、スループットを高く保つことができる

#### LSMツリーのマイナス面

- コンパクション処理が実行中の読み書きのパフォーマンスに影響がある
  - コンパクション処理が終わるまで、リクエストがディスク待ちになってしまうことが生じる
  - 高いパーセンタイルではクエリのレスポンスタイムが悪くなってしまうことも
- 書き込みスループットが高くなる
  - ディスクの帯域（単位時間あたりに処理できるデータ量）は有限
  - 元々の書き込み（ロギング＆MemTableのディスクへのフラッシュ(ディスク上に書き出すこと)）とコンパクションのスレッドの間で帯域を共有する
  - データ量が増えてくると、新しいSSTableの書き出してから古いSSTableの削除という作業に帯域を奪われてしまう
  - コンパクションが追いつかなくなると、マージされないセグメントの数が増えるので、読み取り時に調べるセグメントファイルが増えるので読み取り速度も低下する
- 対してBツリーは、それぞれのキーのインデックスが1箇所にしか存在しないことがメリット（log-structuredストレージエンジンは同じキーのコピーが異なるセグメント中に複数置かれるかもしれない）
  - なので、Bツリーは強いトランザクションのセマンティクス(意味・性質)を提供したいデータベースにとって魅力的

### その他のインデックス構造

- ここまではキー・バリューインデックスのみを論じてきた
  - これはRDBにおけるプライマリキーのインデックスのようなもの
  - プライマリキーは、リレーショナルデータの中の1つの行の頂点をユニークに特定できるもの
    - インデックスはその参照の解決に使われる
- セカンダリインデックスも広く使われている
  - キー・バリューインデックスから容易に構築可能
  - 主な違いはキーがユニークではないこと（すなわち同じキーを持つ行が大量に存在する可能性がある）
  - これの対処として、
    - 全文検索インデックスのように、マッチする行の識別子のリストにする
    - それぞれのキーの行に識別子を追加してキーをユニークにする

### インデックスへの値の保存

- 実際の行 or 別の場所に保存されている参照を返す
- 行が保存されている場所はヒープファイルという
  - ヒープファイルは、ただ順番にレコードを積み重ねる方式
  - 更新するケースで新しい値の方が大きい場合、インデックスを書き換えるか、古い値の方を新しい移転先を指すポインタに変更する
- このようにインデックスからヒープファイルに至る過程でホップが発生してしまうと、読み取り時の処理支援が発生する
  - インデックス付けされた行を直接インデックス内に保存する方法として「クラスタ化インデックス」がある
  - **InnoDBでは、テーブルのプライマリキーは必ずクラスタ化インデックスとなり、セカンダリインデックスはヒープファイル中の場所ではなく、プライマリキーへの参照となる**
- クラスタ化インデックスと非クラスタ化インデックスの中間位置に存在するのが、カバーリングインデックスと呼ぶ
  - カバーリングインデックスはインデックス探索のみでテーブル本体を読まなくて良いもの
  - ageとnameに複合インデックスを貼っておき、`SELECT age, name ~`みたいなイメージ

### 全データのメモリでの保持

- ディスクは「コスト」と「永続性」でメリットがあるが、RAMが安価になるにつれ、コストメリットは失われてきた
  - それがインメモリデータベースの発展につながる
- Memcachedのようなインメモリのキーバリューストアはキャッシュのみを用途とし、マシンの再起動時にデータが失われても許容する
  - しかし他のインメモリデータベースは、耐久性を持つことを目指している
    - 変更ログをディスクに書いたり、定期的なスナップショットをディスクに書いたり、メモリ内の状態を他のマシンにレプリケートしたり..
- 直感に反するが、インメモリデータベースのパフォーマンス上のメリットは、ディスクから読み取りせずに済むことではなく、**メモリ内のデータ構造をディスクに書き込める形式にエンコードするというオーバーヘッドを回避できること**

## トランザクション処理か？分析処理か？

- トランザクション＝クライアントが低レイテンシで 読み書きを行う（バッチ処理と対照的）
  - 商取引などのオンライン処理を指していると理解
- 分析処理＝1月における各店舗の総収入は？など
  - バルクインポートや大量レコード集計が特徴
- これをSQLでうまく捌けていたが、別個のデータベース（データウェアハウス）で分析を行う流れになっていった

### データウェアハウス

- 独立したデータベースで、OLTPの処理に影響を及ぼすことなくアナリストがクエリを実行できる
- 企業内の様々なOLTPシステムのすべてのデータのコピーがリードオンリーで置かれる
- データをウェアハウスに取り込む処理のことをETLと呼ぶ

## 4章 エンコーディングと進化

### データエンコードのフォーマット

- 通常プログラムは、データを少なくとも2つの異なる表現で扱う
  - メモリ上で、オブジェクト・構造体・配列など
    - CPUによるアクセスや操作が効率的になるように
  - ファイルにデータを書いたり、データをネットワーク経由で送信する時は、自己完結にしているバイトの並び（JSONドキュメントなど）としてエンコードする必要がある
    - ポインタは、他のプロセスには全く意味をなさないので、このバイトの並びの表現はメモリ内で通常使われるデータ構造とは全く異なる
- したがって、上記の2つの表現の間で何らかの変換が必要になる
  - インメモリの表現からバイトの並びへの変換は「エンコーディング」や「シリアライゼーション」と呼ばれ、その逆は「デコーディング」「パース」「デシリアライゼーション」「アンマーシャリング」と呼ばれる
- それぞれの言葉の厳密な意味をちょっと調べると、
  - エンコーディング/デコーディング
    - バイト列と文字列や文字コードの変換
    - 文字列"あ"をバイト列 [0xE3, 0x81, 0x82]に変換するみたいな
  - シリアライゼーション/デシリアライゼーション（アンマーシャリング）
    - 複雑なデータ構造（オブジェクトや配列）をバイト列や文字列（JSONなど）に変換する
    - アンマーシャリングは、C言語の文脈で使われることが多い
  - パース
    - 主に文字列を構造化データに変換する処理
    - JSON文字列を辞書型に変換

### JSON,XML,様々なバイナリフォーマット

- 多くのプログラミング言語で読み書きできる標準化されているのは、JSONやXML
- 数値を扱う上での問題点
- バイナリ文字列（文字列のエンコーディングがなされていないバイトの並び）をサポートしていない
  - この制限を回避するのに、Base64を使ってバイナリデータをエンコードする方法が使われる（データサイズが33％増加してしまう）
  - Base64は、3バイト（24ビット）を6ビット分割して、Base64文字セットのインデックスとして対応する文字に置き換える
    - つまり、3バイトを4文字に置き換えるので、33％増加となる

### ThriftとProtocol Buffers

- どちらもバイナリエンコーディングライブラリであり、データのシリアライズフォーマットの一つ
- スキーマを必要とする
- Protocol Buffers
  - バイナリ形式なので、軽量・高速
    - フィールド名が含まれず、フィールド番号と値だけが格納される
  - 言語やプラットフォームに依存しない
- データをバイナリ化するとは？
  - スキーマからフィールド番号と型情報（タグ）を表現
  - 値をバイナリ化（エンコード）する
    - 文字列の場合は長さ＋UTF-8バイト列
  - それらを順番に並べて1本のバイト列にする

### RPC

- RPCモデル
  - リモートにあるネットワークサービスへのリクエストの発行を、同一プロセス内でのプログラミング言語における関数やメソッドの呼び出しと同じように見せる
- 一見便利そうに見えるものの、根本的な問題がある
  - 予測ができない
    - ローカル関数なら自分で制御できるパラメータのみに依存して成功失敗が決まる＝予測できるが、ネットワークなど外部依存となる
  - タイムアウト
    - ローカル関数では存在しない
    - リクエストは到達したのか？結果を受け取れなかっただけなのか？わからない
  - レスポンスだけが失われる
    - 重複排除が考慮されていないとリトライすると複数回アクションが実行されてしまう
  - パラメータをバイト列にエンコードして送る必要がある
    - ローカル関数であれば、オブジェクトへの参照（ポインタ）を渡せば良い
    - プリミティブな値なら大した問題にならないが、大きいオブジェクト等になると問題となる
  - クライアントとサーバーが異なる言語で実装されていることを考慮する必要がある
    - JSの大きい数値問題とか

### RPCの方向性

- 上記のような問題があるが、RPCは無くなっていない
- 公開APIではJSONのようなデバッグに強いフォーマットが向いている
- RPCは、組織内における同一データセンター内のやり取りに使われる

# 第2部 分散データ

### 高負荷に対応するスケーリング

- 最もシンプルなのはスケールアップ
  - コストや耐障害性、地理的な問題など
- 共有ディスクアーキテクチャ
  - CPUやメモリは複数のマシンを使い、ディスクを共有する
  - データウェアハウスのワークロードに使われる
  - スケーラビリティは、競合やロック処理のオーバーヘッドのために制限される
    - 横にスケールするほど、そういった処理が大変になるという意味と理解

### シェアードナッシングアーキテクチャ

- スケールアウトのこと
- 各マシンをノードと呼び、ノード間の調整はソフトウェアレベルで行われる
- 複数の地域に分散し、レイテンシを下げられるのと耐障害性が高い
- ただし、**分散システムに生じる制約やトレードオフは認識する必要がある**

### 複数のノードにデータを分散させる方法

- レプリケーション
  - 同じデータをコピーする
- パーティショニング
  - 小さなサブセットに分割する
  - シャーディングとも呼ばれる
- これらの詳細は後続の章で見ていく

（5章・6章は必要になったら読む）

## 7章 トランザクション

- ACID
  - Consistency: 一貫性
    - データが適正かどうかはアプリケーションが決めること（DBはただデータを保存するだけ）
    - なので厳密にいうと、CはACIDに含まれない（というのが筆者の主張）

### トランザクション分離レベル

- Read Committed
  - ダーティリードが生じない
    - 読み込むデータはコミット済みのデータのみ
  - ダーティライトが生じない
    - 更新できるデータはコミット済みのデータのみ
  - ほとんどのRDBMSのデフォルト値
  - どのように実装されているか？
    - ダーティライトを防ぐ
      - 該当行のロックを取得し、処理終了まで保持し続ける
    - ダーティリードを防ぐ
      - 読み取る行のロックするというのは行わない
        - 書き込みトランザクションの待ち状態が多く発生し、パフォーマンスに影響が出るため
      - 代わりに、データベースは「コミット済みの古い値」と「トランザクションが設定した新しい値」の両方を覚えている
- スナップショット分離
  - 2つの銀行口座にそれぞれ$500入っており、一方からもう一方に$100を送金した場合に、運悪く$400, $500と見えてしまう可能性がある
  - これを解決するのが「スナップショット分離」
  - トランザクションが開始された時点でのデータベースの状態（＝スナップショット）を参照することで、他のトランザクションによるデータの変更から影響を受けずに一貫した読み取りが可能となる
  - MVCC（Multi-Version Concurrency Control）モデル
  - MySQL InnoDBでは以下の2つの隔離レベルがある
    - READ COMMITTED
      - 各SELECTを行うたびにぞの時点の最新のスナップショットを参照する
      - これにより同じトランザクション内であっても、SELECT文を実行するたびに他のトランザクションによってコミットされた変更を参照する可能性がある
    - REPEATABLE READ
      - トランザクションが開始された時点のスナップショットを、そのトランザクションが終了するまで一貫して参照する
      - これがデフォルト値
  - どのように実装されているか？
    - 「ダーティリードを防ぐ」の仕組みを汎用化したもの
    - クエリごとに個別のスナップショットを持つ必要がある
    - 具体的には、トランザクションごとにIDを発行することで、更新前・削除前のデータを取得できるようにしている（MySQLの場合はUndoログから引っ張ってくる）
    - PostgreSQLの場合では、それぞれの行にdeleted_byフィールドがあり、最初は空で、あるトランザクションで削除されるとトランザクションIDが格納され、削除されたというマークになる
      - その後、削除前の状態にアクセスするトランザクションが存在しないことが確実な時に、データベース中のガベージコレクションのプロセスがその行を取り除き、その領域を解放する
      - 更新は、内部的には「削除＋作成」に変換される
    - MySQLのログに関しては以下の記事が簡潔にまとまっていてわかりやすかった
      - https://zenn.dev/enumura_zenn/articles/74d29a8e73973f
  - インデックスの挙動（MyQL）
    - ある行が複数のトランザクションによる更新で複数のバージョンが存在する場合、インデックスは常に最新のコミット済みバージョンの行を参照する
    - 更新時は、元のデータをUndoログに書き込み、元の行のヘッダーにUndoログへのポインタを設定する
    - SELECT時に、トランザクションIDなどのヘッダ情報を見て、可視なバージョンを探し出す
  - スナップショット分離は、MySQLでは「リピータブルリード」と呼ばれる
- 更新のロストの回避
  - 2つのトランザクションが並行に書き込みを行った際に、2つ目の変更は1つ目の変更を踏まえていないので、1つ目の変更が失われる
  - これを解決する方法
    - アトミックな書き込み操作
      - 読み取り時に排他ロックを取り、更新の適用が終わるまで他のトランザクションがそのオブジェクトを読めないようにする
    - 明示的なロック
