# AWS設計スキルアップガイド

## 2.クラウドのインフラ設計

### クラウドで考えるセキュリティ

- 万が一の事故や障害が発生したときに「責任分界点」を定義しておくことで、責任の所在を明らかにできる
- AWSでの「責任共有モデル」では、それぞれの責任について以下のように定義されている
  - AWS: サービスを提供するためのインフラストラクチャ
  - 利用者: 選択したAWSサービスごとの適切なセキュリティを実装し、システムを保護する
- AWS SecurityHubを使用することで、横断的にセキュリティの問題を検知することができる

## 3.システムの構成

- AWSでシステムを構築する時にまず考えるべきは「アカウントをどの単位で発行するか」

### AWSアカウントの運用例

- 単一のアカウントで運用するケース
  - 注意ポイント
    - VPCをプロジェクトや環境ごとに分離する
    - プロジェクトや環境がわかるようにタグを活用する
    - VPCに関連のないサービスを使用する場合、IAMで権限を設定する
  - 管理する請求先が1つになるメリットはあるが、誤操作等によるミスや事故リスクが上がるので、**できればアカウントは分けて運用するのが良い**
- 複数のアカウントで運用するケース
  - アカウントの統制を考慮する
    - AWS ControlTowerで一元管理
    - Organizationで多数のAWSアカウントを管理
  - ログインIDの統合を検討する(1つのユーザーアカウントで各AWSアカウントにログインできるようにする)
    - 各環境のIAMロールで行う方法
    - AWS IAM Identity Center (SSO)を活用する方法
    - サードパーティIDaaSを活用する方法
- (追記)
  - AWS ControlTowerを利用すると、マルチアカウント環境を一元的に整備してくれる
  - 参考: [スタートアップにおけるマルチアカウントの考え方と AWS Control Tower のすゝめ | AWS Startup ブログ](https://aws.amazon.com/jp/blogs/startup/multi-accounts-and-control-tower/)

### IAM

- 認証はIAMユーザー、認可はIAMポリシーで設定する
  - 通常、ポリシーはグループもしくはロールに付与する
  - なぜなら、ユーザーにポリシーをアタッチすると、運用工数がかかる

#### IAMポリシー設計

- デフォルトはすべて拒否なので、明示的に許可していく
  - どのリソース(Resource)に対して、どんな条件で(Conditions)、どんな動作(Action)を、許可/拒否する(Effect)かをJSONもしくはGUIで記述(選択)する
- ポリシーはいくつか種類がある(使用頻度が高いものを抜粋)
  - アイデンティティベースのポリシー
    - アイデンティティ(ユーザー、グループ、ロール)にアタッチする
    - この中にも再利用可能な管理ポリシーとインラインポリシーが存在(管理ポリシー推奨)
  - リソースベースのポリシー
    - S3などのリソースにアタッチする
  - セッションポリシー
    - 一時的にセッション単位でアクセスを許可するポリシー
    - AssumeRoleなどのAPIを利用する
- ポリシー評価について
  - 以下の順番で評価される
    - ![image](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yamasaki/20220227/20220227092451.png)
      - 画像引用元: [【入門編】AWSにおけるアクセスポリシーの評価ロジックを整理してみる](https://blog.serverworks.co.jp/iam/policy/evaluation-logic)
  - 明示的な拒否があれば、その拒否設定が適用される
    - 拒否設定の後に、明示的な許可設定があったとしても、拒否設定が優先的に適用される
  - 明示的な許可があれば許可となるが、なかった場合は暗黙的に拒否される

## 4.ネットワーク設計

### オンプレミスとの比較

- オンプレミスと比較すると、AWSにおけるネットワーク設計はある程度ざっくりでOK
  - 名前解決
    - オンプレミス: 内部DNSを立てるか各サーバーのhostsファイルを利用して名前解決を行う
    - AWS: 自動でパブリックのDNS名が割り当てられ、マネージドのDNSで名前解決を行う
  - 時刻同期
    - オンプレミス: システム内の時刻が同期するように同一のNTPサーバーを割り当てる
    - AWS: AmazonTimeSyncServiceで同期する(インターネット接続不要)
      - マネージドNTP
      - VPCで実行されているすべてのインスタンスの 169.254.169.123 IPアドレスで NTP を介して利用できる
      - 最新バージョンのAmazonLinux2とAmazonLinuxAMIはデフォルトでAmazonTimeSyncServiceと同期してくれている
        - LambdaやECS on Fargate等のマネージドサービスではAWS側で時刻同期されているはずとのこと
        - [AWSマネージドサービスの時刻同期はAWS側で行われているのか | AWS re:Post](https://repost.aws/questions/QUvug7LNsXTQacKVF-AFT9lw/aws%E3%83%9E%E3%83%8D%E3%83%BC%E3%82%B8%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E6%99%82%E5%88%BB%E5%90%8C%E6%9C%9F%E3%81%AFaws%E5%81%B4%E3%81%A7%E8%A1%8C%E3%82%8F%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%81%AE%E3%81%8B)

### VPCとサブネット

- VPCはリージョンごとのサービスなので、リージョンを跨ぐことはできない
- サブネットではいくつかのIPアドレスがAWSの予約枠として確保されている
  - ネットワークアドレス (最初のIPアドレス)
    - 例: 10.0.0.0/24サブネットの場合、10.0.0.0がこのアドレスです。
    - 役割: ネットワーク自体を表すためのアドレスであり、ルーティングやネットワーク構成で使用されます。
  - VPCルーター (2番目のIPアドレス)
    - 例: 10.0.0.1がこのアドレスとなります（サブネットによって異なる場合もあり）。
    - 役割: サブネット内での通信を管理する仮想ルーターです。インスタンス間の通信やインターネットゲートウェイ、VPN接続の経路制御など、サブネット内のルーティングに使用されます。
  - DNSサーバー (3番目のIPアドレス)
    - 例: 10.0.0.2です。
    - 役割: AWSが提供するDNSリゾルバーのIPアドレスです。VPC内のインスタンスがDNSクエリを行う際に使用します。独自のカスタムDNS設定を行わない限り、このアドレスがデフォルトでDNSリゾルバーとして機能します。
  - 将来の用途のために予約されたアドレス (4番目のIPアドレス)
    - 役割: 現時点で特定の用途が明確には指定されていませんが、AWSが今後の機能拡張や内部用途のために予約しています。
  - ブロードキャストアドレス (最後のIPアドレス)
      - 例: 10.0.0.255/24サブネットの場合、10.0.0.255がこのアドレスです。
      - 役割: ブロードキャスト通信のために予約されていますが、AWSのVPCではブロードキャスト通信はサポートされていないため、実際に使用することはありません。

### セキュリティグループ・ネットワークACL・AWS Network Firewall

- AWS Network Firewallは有料なのであまり使われない
- セキュリティグループ(SG)→ネットワークACLと、フィルタの範囲を狭めて、シンプルな構成・運用にする
- SGは、同一SGに所属しているノード同士の通信でも明示的に許可する必要がある

### ルートテーブル

- ルートテーブルは複数のサブネットで共有可能
- サブネット作成時にルートテーブルも作成され、追加の設定なくVPC内の通信は可能
  - デフォルトで、VPC内の全てのサブネットに向けたローカルルートが設定されているため
  - ということは、同じVPC内のサブネットに存在するリソース間で通信を拒否したい場合は、セキュリティグループで設定する必要がある

### VPCエンドポイント

- 異なるVPCやリージョンに配置されたAWSサービスへインターネットを経由せずに接続するサービス
- ゲートウェイエンドポイント
  - ルートテーブルでAWSサービスへのルートを指定
  - 費用かからない
- インターフェイスエンドポイント
  - VPCのプライベートIPアドレスを使用してアクセスする
  - ENIとしてVPC内に配置され、それがサービスに接続するためのエンドポイントとして動作する
  - 処理するデータ量に応じて課金される
- 例えばS3は、どちらでも接続可能だが、インターフェイスエンドポイントの方がセキュリティグループでトラフィックを制御できるため、セキュアである
  - VPC内のリソースがエンドポイントに対して、どのように通信できるかを詳細に制御ができるため、という意味(IPやプロトコル等の制限が可能)

### VPCフローログ

- VPC内のネットワークインターフェースに流れる情報をキャプチャし、ログに記録する
- 監査に必要なログを出力したり、通信がうまく通らない場合はトラブルシューティングとして出力したり
- フローログは以下の3つの項目を指定する
  1. フローログを取得するリソース(VPC/サブネット/ENIをもつELBやNATGateway等)
  2. どんなトラフィックをキャプチャするか(許可、拒否、全て)
  3. フローログの出力先(CloudWatch Logs/S3)

### AWSにセキュアに接続する

- AWS Client VPN
- サイト間VPN
- Direct Connect


## 5.コンピューティング

### Lambda

- イベント駆動型のアプリケーションで使いやすい
- コールドスタートにかかる時間を短くする方法
  - VPC内にアクセスしない(ENI作成に10〜30秒かかるため)
    - VPC Lambdaと呼ばれてるやつ
    - Lambdaをパブリックサブネットに配置するとENIが作成されアタッチされる
    - そのENIに対し、パブリックIPを付与(アドレス関連付け)してやれば、Lambdaからアウトバウンドの通信ができるらしい
  - メモリ増やす(メモリ量に比例してCPUも増加する)
  - コード量を短くする
    - 関数の初期化や依存解決の速度の向上が見込まれるため

#### Lambdaのセキュリティ

- IAMを最小限にする
  - 特定の条件下で特定のリソースに対して実行できるアクションのみ定義する
  - 基本的には複数のLambda関数でIAMロールで共有しない

#### Lambdaの監視

- Lambda関数をデプロイすると自動でCloudWatch Logsと連携する＋レイテンシやエラー率などのメトリクスも自動で発行する
  - エラーを検知できるようにアラートを設定しておくと良い
  - 特にDuration(所要時間)やThrottles(同時実行上限を超えて制限した数)は、エラーが発生する前に適切検知できるようにしておく

### EC2

- インスタンスタイプの書式
  - [Amazon EC2 インスタンスタイプの命名規則 - Amazon EC2](https://docs.aws.amazon.com/ja_jp/ec2/latest/instancetypes/instance-type-names.html)
  - オプション
    - コンピューティング最適化: CPU大きめ
    - メモリ最適化: メモリ大きめ

#### AMI

- インスタンス起動するのに必要なOSやボリューム・アプリケーションを含むテンプレート
- OSのライセンス費用はEC2の利用料金に含まれている(オンプレと異なる点であり、メリットである)

#### インスタンスの費用削減

- リザーブドインスタンス
    - 時間単位の費用を削減できる
    - 1年や3年の長期使用を約束する
    - インスタンスクラスの変更しない場合、または負荷増加の際にオンデマンドインスタンスやスポットインスタンスで対応できる場合に検討する
    - 実際の使用有無に関わらず、購入した条件に応じた期間の費用が発生する
- SavingsPlans
    - これも1年や3年の長期使用を約束する
    - リザーブドインスタンスとの違いは、LambdaやFargateでも使用可能である点、インスタンスファミリーやプラットフォームなどを指定しなくて良い
        - 逆にRDSやElasiCacheでは使用できないので注意
    - 3種類がある
    - インスタンスタイプや構成を柔軟に変更する予定がある場合は、SavingsPlansを検討する
- スポットインスタンス
    - AWSクラウド内の使用されていないEC2キャパシティを活用し、中断される可能性がある
    - なので、本番環境で常時起動するサーバーではなく、ECS実行環境やCICDのビルド環境、バッチに適用する
    - 本番環境で適用する場合は、AutoScalingグループでオンデマンドインスタンスとスポットインスタンスの割合を指定する等して、中断が影響しないようにする
        - 中断の2分前にAWSから警告が来るので、アプリケーションの安全な停止や、ログの退避などは自動で対応できるように実装する
        - インスタンスメタデータで中断対象か確認できる
            - インスタンスメタデータを取得できるAPIがあるっぽい
            - そこを定期的に叩くことで確認

#### T系インスタンスの注意点

- 汎用のT系はM系よりも安価でありよく選定されるが、バーストパフォーマンスインスタンスであることは十分に理解が必要
- バーストパフォーマンスインスタンスとは
    - ベースラインと呼ばれるCPU使用率がある
    - そのベースラインに対して、下回る間はクレジットを獲得し、超える間は消費する
        - 1CPUクレジット=1vCPU×100%使用率×1分
        - つまり、1vCPUを50%使用率で2分使用すると、1クレジット消費するということ
    - 24時間の間で、獲得したクレジットよりも消費するクレジットが多い場合に、その分のvCPU費用が発生する
    - T系インスタンスの各タイプで、1時間あたりに受け取るクレジットや蓄積可能なクレジット、ベースライン使用率は決められている
- CPUクレジットの消費タイプには以下の2種類がある
  - Standard: 残高が0になると、ベースライン使用率以下でのみ使用可能となる
  - Unlimited: Standardのような制約はない代わりに、CPUクレジットが0になった後は、vCPU時間ごとに均一追加料金が発生する（他のインスタンスタイプの利用料金を超える可能性がある）
- 重要なのは、CPU使用率を監視すること
  - CloudWatchメトリクスで参照可能
  - [バーストインスタンスの CPU クレジットをモニタリングする - Amazon Elastic Compute Cloud](https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/burstable-performance-instances-monitoring-cpu-credits.html)
- 参考: [バーストパフォーマンス(T系)インスタンスの特徴を理解して上手に利用しよう | AWS Startup ブログ](https://aws.amazon.com/jp/blogs/startup/burstable-performance-instances/)

### コンテナ

- 仮想化とコンテナの違い
  - ゲストOSの有無が大きな違い
  - 仮想化はホストOSを介して、ハードウェアを制御するため、オーバーヘッドが大きい
  - コンテナは、アプリケーションの動作環境を隔離していて、カーネルはホストOSに依存するため、仮想化のように複数の異なるOSを稼働させることはできないが、逆に言えばOSがない分起動が早く、使用するリソースも少なくて済む

#### コンテナとEC2の違い

- EC2上でコンテナを実行するのと、ECSやEKSなどのオーケストレーションツールを使用するのとでどのような違いがあるのかという問いと同義
- EC2上で動かした場合、デプロイする時は、EC2アプリケーションを更新→AMIを取得→AutoScaling対象のAMIを変更するという、とても面倒な手作業が発生する
  - 逆にロールバックの作業も面倒..
  - 加えて、OS更新等の手作業も発生する
- 一方、ECSの場合は、コンテナやOSの障害や更新をAWS側が管理してくれる
  - CI/CDパイプラインを構築すれば、アプリケーション変更から適用まで迅速に行える
  - コンテナがプロセス落ちを管理し、再度デプロイしてくれる(Serviceがやっていることかな？)

#### コンテナを構成するサービスの特徴

- 複数の環境を有するシステム
  - 再現性が高い特徴を活かせる
- 更新頻度が高いシステム
- アクセス増減の発生が高いシステム
- もはやこのご時世的にはあえてEC2を選択するケースはないのではと思う

#### コンテナサービスを作るときに気をつけること

- 障害発生することを前提とする
  - プロセスが落ちても、すぐに起動できるように
  - ECS Serviceを使えという話だと思う
- 環境差異は変数化する
- ログ出力を1本化する
  - コンテナは実行環境であるホストOS上でプロセスとして動作し、他のプロセスから隔離されている
  - コンテナ内部でアプリケーションログを吐いても、プロセス停止した際などにログが残らなくなってしまう
  - ホストOSか別の領域に出力するように設定する
    - ちょっと調べた感じ、タスク定義でログドライバにawslogsを設定し、ロググループなども設定すれば、1つのロググループに出力されるようになるっぽい
- 1コンテナ1プロセスとする
  - 1つのコンテナに複数のプロセスを稼働させることも可能だが、制御が難しいため

#### Amazon ECS

- ECSの構成要素
  - クラスター：実行環境
  - タスク定義：指定のコンテナを動かす
  - サービス：全体の構成やデプロイ方法を設定
- タスク定義
  - 主な設定項目
    - Dockerイメージ
    - コンテナのCPUとメモリ
    - データボリューム
    - IAMロール
    - コンピューティング環境(EC2 or Fargate)
- サービス
  - 主な設定項目
    - 連携するELBを指定
    - 指定したタスク定義のタスク数
    - デプロイ方法(Blue/Green,ローリングアップデート)
    - 実行環境(EC2,Fargate)で待ち受けるポートや、コンテナ側で待ち受けるポートも指定する
  - サービスはなくても動くけど、AutoScalingの実装等に必要
- クラスター
  - 主な設定項目
    - コンテナ実行環境のネットワークを指定
    - 起動するインスタンスタイプやAMI、その数を指定
  - Fargateの場合は、ネットワーク作成とクラスター名のみを設定する

#### タスク定義の更新
- コンテナイメージにつけるタグ名はlatestにするとタスク定義の修正が不要になる一方、コンテナイメージのバージョンがわからないのがで名rっと
- デプロイ方法「ローリングアップデート」と「Blue/Greenデプロイメント」がある
  - ローリングアップデートの例
    - DesiredCountを4に、minimumHealthyPercentを0.5に設定した場合、4 * 0.5の2インスタンスが更新されたタスク定義を元に作成される
  - Blue/Greenデプロイメントの例
    - タスク定義を更新すると、新たにGreen環境が作成あれ、疎通に問題がなければ、LBのレイヤーで切り替えを行う（だからLBが必須）

#### データボリューム
- ログや共通のデータはコンテナ外に領域を確保する
- ECSで選択可能なデータボリュームは以下になる
  - EFS
  - FSx for Windows File Sever
  - Dockerボリューム
    - EC2のみ利用可能
  - バインドマウント
    - ホスト上のファイルやディレクトリをコンテナからマウントする
  - Fargate タスクエフェメラルストレージ
    - エフェメラルストレージ=一時的なストレージ
    - プロビジョニング時にECSタスクが受け取るもの
    - これらをマウントし、タスク定義内でvolumes、mountPointsおよびvolumesFromパラメータを使用しているコンテナ間で共有することが可能
  - [Amazon ECS タスクのストレージオプション - Amazon Elastic Container Service](https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/using_data_volumes.html)

## 6.データベース

### データベースの選択

- どんな用途なのかと移行か新規なのか、複数の観点からの検討が必要

### RDS

- EC2同様に仮想サーバー上で実行される
- EC2でもDBの構築は可能だが、RDSと異なり自動スケーリングや高可用性、OS・DBソフトウェアのパッチ適用などはユーザーが設計・実装・運用する必要がある
  - 逆に、その辺りを自前で管理したい・RDSでサポートされていないパラメータをチューニングしたい・開発環境などで費用削減をしたいという場合はEC2でのDB構築が選択肢になる
- リクエストのI/Oサイズやアクセスパターンにより、パフォーマンスが大きく変わる
  - シーケンシャルなアクセスでは、最大I/Oサイズに達するまで、単一のI/O操作に含められる
  - ランダムなアクセスでは、最大I/Oサイズに達しない小さいサイズでも、IOPSに個別カウントする
    - つまりランダムアクセスの場合はIOPSの消費が多いので、それを考慮してインスタンスクラスなどを決めようという話
- パフォーマンスは、DBで最も重要な非機能要件になるので、机上確認だけでなく、実際に検証したり、CloudWatchメトリクスで確認したりして、ストレージタイプを選ぶと良い

#### マルチAZ構成

- サポートされている機能は、リージョンやデータベースエンジンによって異なる
- マルチAZデプロイすると、Read/WriteできるプライマリDBインスタンスとフェイルオーバー先となるスタンバイレプリカ(読み取り書き込みはできない)が別AZへデプロイされる
- スタンバイレプリカは通常時は動作せず、プライマリに障害が発生した時にレプリカが昇格する
- フェイルオーバーは60〜120秒

#### マルチAZ DBクラスタ

- 1つの読み取り/書き込みインスタンスと、2つ以上の読み取り専用スタンバイDBインスタンスで構成
- 読み取り/書き込みインスタンスに障害が発生したら、読み取り専用スタンバイDBインスタンスが昇格
- 書き込み専用DBインスタンス接続するクラスタエンドポイントと、読み取り専用に接続するリーダーエンドポイントがある
  - エンドポイントは、クラスタ内の対象インスタンスに接続できない場合に自動的に接続先を変更する
- フェイルオーバーは35秒未満

### RDS Proxy

- RDSでは、アプリケーションからの接続を処理する際にメモリやCPUを消費する
- 頻繁に短時間でDB接続を繰り返すアプリケーションでは、DBの処理負荷を下げるためRDS Proxyを導入すると良い
- RDSの最大接続数はパラメータグループのmax_connectionsで定義されており、手動変更は推奨されていない
- そのため、同時接続数が上限に達しそうな場合は、上位のインスタンスクラスorRDS Proxyを検討する
- RDS Proxyの特徴
  - フルマネージドサービス
  - アプリケーションとRDSの間に設置
  - VPC内の異なるAZにある2サブネットを選択して作成
  - RDS Proxyを間に配置することによる遅延は5ミリ秒程度
  - RDSのインスタンスレベルを上げずに済むので、コストや運用工数を抑えられる
- RDS Proxyを採用するメリット
  - フェイルオーバーにかかる時間を短縮できる
    - 数秒レベルでフェイルオーバーが完了する
    - RDS Proxyがない場合は、スタンバイの昇格とクラスタエンドポイントの更新後にアプリケーションが再接続するのに比べて、RDS Proxyがある場合はアプリケーションからの接続をプールし、RDS ProxyからRDSへの接続は処理中であったものを除いて保持・再利用するため
      - この箇所ちょっと引っかかったので調べてみた。
      - RDS Proxyの使用有無で、RDS側のフェイルオーバーにかかる時間は変わらないと思う
      - ただし、アプリケーションの視点で見た時に、RDS Proxyへのコネクションを再確立する必要がない
        - RDS ProxyーRDS間のコネクションの再確立のみで不要
        - なので、アプリケーション側からすると、再接続するオーバーヘッドがかからないので、フェイルオーバーにかかる時間を短縮できると表現されていると思われる(RDS側のDNS更新も待つ必要もない)
- RDS Proxyを利用する際の注意点
  - IPアドレスの枯渇
    - RDS Proxyは、接続先RDSのインスタンスクラスと台数に応じて自動的に容量を増減し、場合によっては多くのIPアドレスを利用する
    - IPアドレスが枯渇するとうまくスケールができず、クエリ遅延やコネクション失敗が発生することがある
    - インスタンスクラスごとに確保すべき最小IPアドレス数が定められている
    - あくまで、IPアドレスを消費するのは、RDS Proxy-RDSの接続