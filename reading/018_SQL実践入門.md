# SQL実践入門

## 1章 DBMSのアーキテクチャ

- エンジニアとして特に押さえておくべきは「クエリ評価エンジン(実行計画)」で次点で大事なのが「バッファマネージャー」
- バッファ
  - メモリからデータを取った方が当然速い
  - バッファは緩衝材という意味で、この文脈ではユーザーとストレージの間に入って、ディスク減らす役割を果たす
  - このバッファにどれくらい何を入れておくかを管理するのが、バッファマネージャー
- キャッシュはユーザーとストレージの中間に位置することでデータの転送緩和する
- キャッシュもバッファも、物理的な場所としてメモリなのは同じ
- 2つのバッファ: データキャッシュとログバッファ
  - 更新SQLを受け取ったら、まずはログバッファに更新情報を溜めている
  - コミット時にディスクに反映する
  - わざわざこんなことをするのは、更新にも多大な時間がかかるので、パフォーマンスを良くするため
- ここまでのバッファの説明で、結局DBMSはストレージの遅さをどうカバーするかということをずっと考えてきた
- バッファ(メモリ)の揮発性の問題点は、コミットのタイミングで必ず更新情報を永続ストレージ上にあるログファイルを書き込むことで解決
- 各DBMSのログバッファのサイズが小さい理由は、データベースは検索を想定しているため。データキャッシュに割くようにしている。
  - もし更新量が多い業務の場合はログバッファのサイズを大きくするチューニングを行う
- 2つのバッファ以外ではワーキングメモリというメモリ領域がある
  - ソートやハッシュなど特定の処理に利用される作業用領域
  - ワーキングメモリが溢れるとTEMP落ち(ストレージ領域なので遅い)
  - メモリ不足だと落ちるわけではなく、何とかして処理継続しようとするのがDBMS
- データアクセスの手続きを決めるモジュールはクエリ評価エンジン
  - パーサー：構文解析
  - オプティマイザ：実行計画の決定。最適化。最もコストが低い計画を絞り込む。
  - カタログマネージャ：内部情報を保持。テーブルやインデックスなどの統計情報。
  - プラン計画：オプティマイザが組み立てた複数の実行計画から最適な実行計画を選択。
- ポイントはオプティマイザをうまく使ってあげる
  - 統計情報が不適切だと最適なプランは選択されない
  - 統計情報更新は手動でも可能
- SQLで遅延が発生したら
  - まずは実行計画を確認する
- 実行計画の見方
  - フルスキャンとインデックススキャン
    - 行数が多いとインデックススキャンが効いてくる
  - rowsは、オプティマイザが実行計画を作るときにカタログマネージャーから取得するテーブル情報(統計情報)が元になっているので実際の行数とは乖離することがある
  - 結合
    - SQLが遅いケースの十中八九は結合が関係する
- 結合アルゴリズム
  - NestedLoop
    - 1行のレコードに対して、結合条件に合致するレコードを取得
  - SortMerge
    - 結合キーでソートしてから、順次アクセスを行い、2つのテーブルを結合
    - 結合前にソートを行うのでそのためのメモリ領域(ワーキングメモリ)が必要
  - Hash
    - 結合キーの値をハッシュ値にマッピング
    - ハッシュテーブルを確保するための作業用メモリ領域が必要
- オプティマイザも完璧ではない
  - 最終手段はヒント句をSQLに埋め込みオプティマイザに強制的に命令を出す

### 結合アルゴリズム

- **NestedLoops**
  - 最も頻繁
  - 駆動表(結合元)の1行について、内部表(結合先)を1行ずつスキャンする
  - アクセス行数は両テーブルを掛け算した行数、つまり実行時間は行数に比例する
  - 1つのステップで処理する行数がすくないのであまりメモリを消費しない
  - 以下の前提があれば、駆動表の行数が少ない方が性能が良くなる（駆動表(結合元)が小さい＝ループが少ない）
    - 内部表(結合先)の結合キーの列にインデックスが存在する
      - 内部のループをある程度スキップできる
      - 一意であれば、ループは完全にスキップされる。複数行あればその分だけ内部ループは残る
  - **駆動表の小さなNested Loops＋内部表の結合キーにインデックス**という組み合わせはチューニングの基本
    - ERやインデックス設計の段階でここは考慮すべき
  - 落とし穴
    - 内部表が結合キーで一意にならない
      - 例として店舗テーブルがと注文テーブル（駆動表）で、1つの店舗に対して注文テーブルが複数ある場合
    - 対策としては、駆動表をあえて注文テーブルにする（この方法だと70点を取りに行くイメージ）や以下で紹介するHashが選択肢となる
- **Hash**
  - まずは小さいテーブルをスキャンし、結合キーのハッシュ値を計算し（ハッシュテーブルとしてid, hashed_idがあるイメージ）、大きいテーブルをスキャンしてそのハッシュ値が存在するかを調べる
    - なぜ小さいテーブルからハッシュテーブルを作るのかというと、ハッシュテーブルはDBMSのワーキングメモリに保持されるため、なるべく小さい方が効率が良いため
  - （NestedLoopsと比較したときの）特徴として、
    - ハッシュテーブルを作る分だけメモリを多く消費する
    - メモリ内にハッシュテーブルが収まらないとストレージを使用するので遅延が発生する（TEMP落ち）
    - 出力されるハッシュ値は入力値の順序性を保持しないので、等値結合でしか使用できない
  - 有効なケース
    - NestedLoopsで適切な駆動表（相対的に十分に小さいテーブル）が存在しない場合
    - 上記で挙げた店舗--注文のように、内部表のヒット件数が多い場合
    - 内部表にインデックスが存在しない場合
  - 一言で言うと、NestedLoopsが効率的に動作しない場合の次善策がHash
  - ただハッシュテーブルを作る分だけワーキングメモリを食うので、同時実行性の高いOLTPではHashの使用は極力避けた方が良い
    - 夜間バッチやDWHなど
  - また、Hash結合は必ず両方のテーブルを全件読み込む必要があるので、このフルスキャンに要する時間も考慮する必要がある
- **Sort Merge**
  - NestedLoopsが非効率の場合にHashと並んでもう一つ選択肢になるのがこれ
  - 単にMergeやMerge Joinと呼ばれることも
  - 結合対象のテーブルをそれぞれ結合キーでソートを行い、一致する結合キーを見つけたらそれを結果セットに含めるという挙動になる
  - 特徴として、
    - 両方のテーブルに対しソートを行うのでメモリを消費する（Hashよりも多くのメモリを使うことも）
    - 不等号の結合でも利用可（ただし否定条件では利用不可）
    - 原理的には結合キーでソート済みであれば、ソートをスキップできる
    - テーブルをソートするため、片方のテーブルを全てスキャンしたところで結合を終了できる
  - 有効なケース
    - テーブルのソートに多くの時間とリソースが必要な可能性があるので、テーブルのソートをスキップできるかなり例外的なケースでは考慮に値するが、それ以外の場合はNestedLoopsやHashが優先的な選択肢となる
- 知りたいこと
  - それぞれのアルゴリズムは何を元に選定されるのか？
